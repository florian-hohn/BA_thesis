\documentclass[12pt,oneside,a4paper,parskip]{scrbook}
\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\usepackage[english]{babel}
\usepackage{floatflt} 
\usepackage{subfigure}
\usepackage[pdftex]{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{color}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{nicefrac}
\usepackage{pdfpages}
\usepackage{float} 
\usepackage{pdflscape}
\usepackage{subfigure}
\usepackage{pdfpages}  
\usepackage[verbose]{placeins} 
\usepackage[nouppercase,headsepline,plainfootsepline]{scrpage2}
\usepackage{listings}		
\usepackage{xcolor}			
\usepackage{color}			
\usepackage{caption}		
\usepackage{subfigure}			
\usepackage{epstopdf}		
\usepackage{longtable}  
\usepackage{setspace}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{acro}
\usepackage[style=numeric]{biblatex}
\usepackage[toc,page]{appendix}
\usepackage{csvsimple}
\addbibresource{bib_file.bib}
\bibliography{bib_file}
\graphicspath{ {figures/} }


%%%%%%%%%%%%%%%%%%%
%% definitions
%%%%%%%%%%%%%%%%%%%
\def\BaAuthor{Florian Hohn}
\def\BaTitle{Evaluation and implementation of gradient descent algorithms on streaming data}
\def\BaSupervisorOne{Prof.\ Dr.\ Frank-Michael Schleif}
\def\BaSupervisorTwo{Moritz Heusinger}
\def\BaDeadline{25.02.2020}

\hypersetup{
pdfauthor={\BaAuthor},
pdftitle={\BaTitle},
pdfsubject={Subject},
pdfkeywords={Keywords}
}

\newcommand{\R}{\mathbb{R}}

%%%%%%%%%%%%%%%%%%%
%% configs to include
%%%%%%%%%%%%%%%%%%%
\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

\definecolor{gray}{rgb}{0.4,0.4,0.4}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\definecolor{cyan}{rgb}{0.0,0.6,0.6}

\definecolor{pblue}{rgb}{0.13,0.13,1}
\definecolor{pgreen}{rgb}{0,0.5,0}
\definecolor{pred}{rgb}{0.9,0,0}
\definecolor{pgrey}{rgb}{0.46,0.45,0.48}

\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  showstringspaces=false,
  commentstyle=\color{gray}\upshape
  linewidth=\textwidth
}

\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    backgroundcolor=\color{background},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}

\lstset{language=xml,
  morestring=[b]",
  morestring=[s]{>}{<},
  morecomment=[s]{<?}{?>},
  stringstyle=\color{black},
  numbers=left,
  numberstyle=\scriptsize,
  stepnumber=1,
  numbersep=8pt,
  identifierstyle=\color{darkblue},
  keywordstyle=\color{cyan},
  backgroundcolor=\color{background},
  morekeywords={xmlns,version,type}% list your attributes here
}

\lstset{language=Java,
  showspaces=false,
  showtabs=false,
  tabsize=4,
  breaklines=true,
  keepspaces=true,      
  numbers=left,
  numberstyle=\scriptsize,
  stepnumber=1,
  numbersep=8pt,
  showstringspaces=false,
  breakatwhitespace=true,
  commentstyle=\color{pgreen},
  keywordstyle=\color{pblue},
  stringstyle=\color{pred},
  basicstyle=\ttfamily,
  backgroundcolor=\color{background},
%  moredelim=[il][\textcolor{pgrey}]{$$},
%  moredelim=[is][\textcolor{pgrey}]{\%\%}{\%\%}
}


%%%%%%%%%%%%%%%%%%%
%% Abk√ºrzungen
%%%%%%%%%%%%%%%%%%%
\DeclareAcronym{sgd}{
  short = SGD ,
  long  = Stocastic Gradient Descent ,
  class = abbrev
}

\DeclareAcronym{adam}{
  short = ADAM ,
  long  = Adaptive Moment Estimation ,
  class = abbrev
}

\DeclareAcronym{rms}{
  short = RMS,
  long  = root mean squared ,
  class = abbrev
}

\DeclareAcronym{moa}{
  short = MOA ,
  long  = Massive Online Analysis ,
  class = abbrev
}

\DeclareAcronym{lvq}{
  short = LVQ ,
  long  = Learning Vector Quantization ,
  class = abbrev
}

\DeclareAcronym{npc}{
  short = NPC ,
  long  = nearest prototype classification ,
  class = abbrev
}

\DeclareAcronym{rslvq}{
  short = RSLVQ ,
  long  = Robust Soft Learning Vector Quantization ,
  class = abbrev
}

\DeclareAcronym{iot}{
  short = IoT,
  long  = Internet of Things,
  class = abbrev
}

\begin{document}


%%%%%%%%%%%%%%%%%%%
%% Titelseite
%%%%%%%%%%%%%%%%%%%


\frontmatter
\titlehead{%  {\centering Seitenkopf}
  {University of Applied Sciences W\"{u}rzburg-Schweinfurt
  Faculty of Computer Science and Business Information Systems}}
\subject{Bachelor-Thesis}
\title{\BaTitle\\[15mm]}
\subtitle{\normalsize{submitted to the University of Applied Sciences W\"{u}rzburg-Schweinfurt in the Faculty of Computer Science and Business Information Systems to achieve the Bachelor of Engineering degree in 'Information Systems'}}
\author{\BaAuthor}
\date{\normalsize{Submitted on: \BaDeadline}}
\publishers{
  \normalsize{First Reader: \BaSupervisorOne}\\
  \normalsize{Second Reader: \BaSupervisorTwo}\\
}

%\uppertitleback{ }
%\lowertitleback{ }

\maketitle


%%%%%%%%%%%%%%%%%%%
%% abstract
%%%%%%%%%%%%%%%%%%%

\section*{Abstract}
There is an ever growing amount of Data in our everday lives that are produced by sensors when connected to 
the \ac{iot}, used in self-driving cars or used to recognise our speech to take commands from us
(e.g. Amazons Alexa or Apples Siri). But to be of use for us this Data first needs to be analyzied, and this 
becomes a real challenge, as traditinoal Machine Learning algorithm normaly take several runs through a training set before 
the learning process is complete.
Thankfully there are already several Algorithm developed that can train and learn on data by only needing one run on 
these datasets and can therefor process this streamed Data.
Moritz Heusinger looked already into different varients of how a \ac{rslvq} algorithm can be modified to work on streaming data
in \cite{PassiveDriftonRSLVQ} and compared them.
This work will compare an additional varient of how the RSLVQ can be implemented to work on streaming data and will it 
compare to the other three varients of the RSLVQ in terms of accuracy, performance and computation time.

\newpage
\chapter*{Note of thanks}
I want to thank my familiy for always supporting me through the whole time I studied and worked on this thesis as well
as the time I needed to finish my Bachelor of Engineering degree in 'Information Systems'.
I also want to thank Prof. Schleif and Mr Heusinger, as I could always ask them when I was not sure about something while working on 
this thesis and they would then try to help me with my questions.

%%%%%%%%%%%%%%%%%%%
%% Table of Contents
%%%%%%%%%%%%%%%%%%%
\tableofcontents	




%%%%%%%%%%%%%%%%%%%
%% Main part of the thesis
%%%%%%%%%%%%%%%%%%%
\mainmatter

\chapter{Introduction}\label{ch:intro}

The following chapter will give the reader a short explanation what inspired the work for this thesis, what its prupose is 
and what it wishes to achieve, as well as an explanation how this work is structured, to give the reader a better oriantation 
for how to navigate the thesis.

\section{Inspiration for this Thesis} 
There is an ever growing amount of data that needs to be processed in real time to be of use nowadays, e.g. from sensors that 
monitor processes in the industry to improve their quality \cite{MLonDataStreams}, from data streams originating on 
the Internet that can be used to detect epidemics and natural disasters, which can be combined with statistics from 
official centers for disease and disaster control for better prevention \cite{MLonDataStreams} or for the use in selfdriving
cars.
The problem is this flood of data has outpaced our capability to process, analyze, store, and understand these datasets.
Traditional Machine learning algorithms are not capable of learning and training from this flood of data in a acceptable 
amount time. The reason for this, is that the stream can suddenly change, so called "Concept drift". Data is also 
rapidly and constantly generated, which means that the learning algorithm can not use the data more than once to learn 
from it.
For this reasons we need algorithms that can deal with this amount of data in real-time while also needing only a 
reasonable amount of resources \cite{MLonDataStreams}.

Heusinger compared for this reason several varients of how the \ac{rslvq} Machine learning algorithm could be modified
to make it work with stremed data in \cite{PassiveDriftonRSLVQ}.
This work will now take the $RSLVQ_\textit{Adam}$ that was suggested in \cite{overvieDiffRSLVQ} as possible modification 
for the RSLVQ and will compare it with the $RSLVQ_\textit{SGD}$, $RSLVQ_\textit{Adadelta}$ and the $RSLVQ_\textit{RMSprop}$ 
varients, that Heusinger already had compared with each other in \cite{PassiveDriftonRSLVQ},  
in respect to their accuracy, performance and computation time.

\section{Purpose of this Thesis} 
In \cite{PassiveDriftonRSLVQ} was shown that, on average, the $RSLVQ_\textit{Adadelta}$ performance better in nearly
all aspects beside the computation time and the Kappa Performance in respect to the other versions of the RSLVQ 
that were tested in this paper.
It had further shown that with delayed settings the $RSLVQ_\textit{RMSprop}$ performed better than the $RSLVQ_\textit{Adadelta}$
and the $RSLVQ_\textit{SGD}$ implementation.
This work will compare another modfified RSLVQ version, that is based on the ADAM algorithm, with the other already tested
RSLVQ versions when they are used on streaming data. It will compare them in respect to their returned accuracy,
performance and computation time on different synthetic and real data streams with different evaluation approaches.
According to \cite{Kingma2014AdamAM} the $RSLVQ_\textit{Adam}$ should compare favourably in comparison towards the
other adaptive learning algorithms and should therefore be returning the best results in the experiments.


\section{Outline of the Thesis} 

The second Chapter of this thesis will give a short overview over the basics of Machine Learning that are relavant for
the understanding of the premise for the thesis. This paper will provide a short describtion about what is special about Data stream 
in Machine learning algorithms and what is importent to take into account when working with them.
It will also give a short introduction about the criterias with which the comparision of the different implementations 
of the Algorithm take place and why these criteria are used for  comparision.
In the last part of the first chapter the framework will be introduced which was used for implementation and comparision.
The next chapter will then continue to give a deeper look into the more complex parts of the subsection of Machine learning 
and the Algorithm that is the basis for the different variation of implementation for the Algorithms.
It will also give a short introduction about the version that this algorithm was based on, as this is importent to later understand
the variations and differences in the other implementations.
The last part of this chapter will then explain the differnet methods and the implementations of the variants in greater detail.

The fourth chapter will then list and describe the used synthetic and real world streaming data sets that where used to 
perform the experiments.
Furthermore there will be a description how the experiments where conductet and with wich methods the results where controlled.
The following chapter will then be dedicated to the evaluation of the results. 
The last chapter will summarize all the work that was done and give a final evaluation of the algorithms.

\chapter{Basics}
The Goal of this Chapter is to give the Reader a basic understanding of how Machine Learning Algorithm work. 
Furthermore, it will describe what the difference is between unsupervised und supervised learning. 

There will be also an introduction and description on how the Gradient Descent Algorithm, which is the basis for the 
Modified versions of the Algorithms that will be compared in this work, works and how it decides what to do. 
After this is done there will also be a short description on what Streaming Data is and on the framework that is used to 
realise the implementation of the experiments.

Finally there will be an explanation on how the criteria for the comparision of the Algorithms where choosen and how 
theses criteria work.

\section{Machine Learning}

The term 'Machine Learning' stands for a collection of self-learning algorithms, that learn form input Data to make 
fast and correct decisions and predictions. It is importand to remember that it is not a real Artifical Inteligence, 
but rather a sequence of statistical analyses on given data, with the goal to make gradualy improvments to the prediction 
models of the algorithm.  
A Machine can do this optimization a lot faster and more efficiently than a humans, especially if this optimization has to be 
done in real time on big data input sets. This gives also a bigger flexability, as a machine that can learn from a changing 
enviroment needs lesser redesigns, which leads to less time that gets wastet and can be used more productive on other 
tasks. 

All these are reasons why Machine Learning has an ever increasing importance in the field of computer science, 
but also an growing impact on everday life. It is thanks to Machine learning that there are intelligent assisstant 
softwares that can recognize voice commands and questions (Apples SIRI, Amazon Alexa or Microsofts Cortana),
e-mail spam filter, nearly self-driving cars, reliable search-engines, faster and more precise weather forecasts and 
challenging game AI's nowadays 

Machine Learning Algorithms can be categorisized depending on how they learn from the available training Data to create 
a model for the predictions. There are three main subdivisions, under wich these algorithms can fall. 
The first one is the Supervised learning strategy, then the Unsupervised learning strategy and the Reinforced learning 
strategy. 

\begin{figure}
  \includegraphics[width=\linewidth]{Overview_ml}
  \caption{Overview of the Machine Learning Strategy's.}
  \label{fig:overview_ML}
\end{figure}

Only the Supervised Learning strategy will be explained in more detail on the following pages, as the focus of this 
thesis lays in the comparision of several different implementations of classification algorithms that are based on 
Supervised Learning \cite{IntroML}.

\subsection{Supervised Learning}

The idea behind Supervised learning is to create a model from an already labeled training data set, that then can make 
predictions and decisions on new or unknown data based on the learned model from the training set. 
The following example will help to understand this easier.
Lets say a fruit farmer wants to automatically sort the harvested Fruits in either categorie A or B for the market. 
The sorting device is equiepped with 2 sensors to measure 2 features, one for colour and another one for the size of the 
fruit. It then decides to wich of the two classes the fruit belongs to. As this is a System that is capable of dividing 
features into a discrete number of classes the system can be called a \textit{classifier}. 
This is a typical exampel of an \textit{classification task}.
To configure the System in such a way that it correctly sorts the fruits into the right category, 
a specailist hand picks several fruits from a small test set and then sorts them depending on the already named features. 
In other words, the specailist classifies them. Based on this by hand sorted training set the machine will then later 
decide how the other fruits should be sorted. It is used as a \textit{model} for the classification. \cite{IntroAI}
Another type of Supervised learning is the \textit{regression task}. The difference to the \textit{classification task} is, 
that instead of a \textit{discrete} number of classes that gets returned, a \textit{continous} number of classes will be 
returned. An example of a \textit{regressive task} is, for example, the prediction of the Stock market or the price of 
medications.

The Process as seen in figure \ref{fig:sl_process} and as described as in the example of the farmer and his sorted 
fruits shows how the supervised learning works. The Algorithm (marked in green) learns with the help of the labeled 
training data. The result of this learning is then that the trained Algorithm, now called predictive model, 
can be used in a production enviroment.
New, unlabeled, data can then be send into the predictiv model to get a predictied model as an output. \cite{PythonML}

To better understand how this predictiv model is formed, one has to understand how the classification task works. 
In the classification task the computer programm is asked to specify which of \textit{k} catergories a input belongs to. 
To solve this task, the learning algorithm is usually asked to produce a function \textit{f} : $\R{}$ $\rightarrow$ ${1,...,k}$. 
When \textit{y} = \textit{f}(\textit{\textbf{x}}), the model assigns an input described by vector \textit{\textbf{x}} to a 
category identiÔ¨Åed by numeric code \textit{y}.
There are other variants of the classiÔ¨Åcation task, for example, where \textit{f} outputs a probability distribution over 
classes. An example of a classiÔ¨Åcation task is object recognition, where the input is an image (usually described as a set 
of pixel brightness values), and the output is a numeric code identifying the object in the image. \cite{Goodfellow-et-al-2016}

\pagebreak

\begin{figure}[H]
  \includegraphics[width=\linewidth]{SL_process_figure}
  \caption{Process of the Supervised Learning. \cite{PythonML}}
  \label{fig:sl_process}
\end{figure}

Then there must also be a diffenciation between the type of data that is put into the classification process.
In batch or offine classification, a classifier-building algorithm is given a set of labeled examples. 
The algorithm creates a model, a classifier in this case. The model is then deployed, that is, used to predict the label 
for unlabeled instances that the classifier builder never saw. If we go into more detail, we know that it is good 
methodology in the first phase to split the dataset available into two parts, the training and the testing dataset, 
or to resort to cross-validation, to make sure that the classifier is reasonably accurate.
But in any case, there is a first training phase, clearly separated in time from the prediction phase.

In the online setting, and in particular in streaming from big data sets, like it is in this thesis, this separation between training, 
evaluating, and testing is far less clear-cut, as the algorithm has to work with the data that it receives right now and often can only use once,
before new daat arrives that need processing.
There is a need to start making predictions before we have all the data, because the data that arrives never ends. 
The data whose label was predicted needs to be keept to train the model, if possible.
The model also needs to continuously be evaluated in some way to decide if it needs more or 
less aggressive retraining. \cite{MLonDataStreams}

\subsection{Gradient Descent}
The Gradient descent Algorithm is one of the most popular Algorithms to perform optimizations on and is by far the most 
commen way to optimize neural networks.This is also the reason why nearly every state-of-the-art Deep Learning Library 
has various forms of implementations to perform optimization on the gradient descent. The Problem however is that these
Algorithms often perform as some sort of black-box, because a practical explanation of what their stengths and weaknesses 
is are hard to explain.
Gradient descent is a way to minimize an objective function \textit{J}($\theta$) parameterizedby a model's parameters $\theta \in \R{}^d$ by 
updating the parameters in the opposite directionof the gradient of the objective function $\nabla_\theta \in $\textit{J}($\theta$) with respect to 
the parameters. The learning rate $\eta$ determines the size of the steps we take to reach a local minimum. In other words, 
we follow the direction of the slope of the surface created by the objective function downhill until we reach a valley. \cite{overvieDiffRSLVQ}

The normal gradient descent, also known as batch-gradient descent, computes the gradient of the functionwith 
respect to the parameters $\theta$ for the entire training set:

\begin{equation}
\theta = \theta - \eta * \nabla_\theta \textit{J}(\theta)
\end{equation}

Since we need to calculate the gradients for the complete dataset to get just one update, batch gradient descent can get very
slow and is intractable for datasets that do not fit into the memory. For this reason the batch gradient descent implementation
can not be used in this comparison, as it is not able to perform updates "on-the-fly", as this is a necessarity for use on streaming Data. 

In contrast to that, the \ac{sgd} can perform a update for \textit{each} training example
$\textit{x}^\textit{(i)}$ and label $\textit{y}^\textit{(i)}$:

\begin{equation}
\theta = \theta - \eta * \nabla_\theta \textit{J}(\theta;\textit{x}^\textit{(i)};\textit{y}^\textit{(i)})
\end{equation}

While the bacht gradient descent performed redudant computations for large datasets, as it recomputes gradients for similar examples 
before each update, the SGD puts away this redundacy by performing one update at a time. Because of that it performs much faster and 
can be used on Streaming Data.
The SGD performs frequent updates with a high variance, that causes the objective function to fluctuate heavily. 

\begin{figure}
  \centering
  \includegraphics[width=0.7\columnwidth]{Gradient_desc_types}
  \caption{Visualisation differences of the three Gradient Descent Algorithms}
  \label{fig:comp_GD}
\end{figure}

This fluctuation enables the SGD to jump to new and potetially better local minima, while the batch gradient only converges 
to the minimum of the basin the parameters are placed in. But this also ultimatly complicates the convergensto the exact minimum, 
as the SGD keeps overshooting. This can be fixed by slowly decreasing the learning rate, as the SGD then shows the same 
convergeance behaviour as the batch gradient descent. It then almost certainly converges to a local or gloabl minimum for
non-convex and convex optimization respectively. \cite{overvieDiffRSLVQ}
These advantages lead to the fact that the SGD is the most common Gradient descent algorithm.

Then there is also the Mini-batch gradient descent algorithm. It takes the best of both worlds and performs an update for
every mini-batch on \textit{n} training examples:

\begin{equation}
\theta = \theta - \eta * \nabla_\theta \textit{J}(\theta;\textit{x}^\textit{(i:i+n)};\textit{y}^\textit{(i:i+n)})
\end{equation}

This way it reduces the variance of the parameter updates, which can lead to a more stable convergence.
It can also make use of highly optimized matrix optimizations common for state-of-the-art deep learning libraries,
that makes computing the gradient with respect to a mini-batch very efficient. 
Common mini-batch sizes range between 50 and 256 , but can vary for different applications. Typically the Mini-batch gradient descent is the 
algorithm of choice when there is a neural network to train and the term SGD is usually also employed even when mini-batches
are used. \cite{overvieDiffRSLVQ}

\pagebreak

\section{Streaming Data}

Data streams are an algorithmic abstraction to support real-time analytics. They are sequences of items, 
possibly infinite, each item having a timestamp, and so a temporal order. Data items arrive one by one, 
and we would like to build and maintain models, such as patterns or predictors, of these items in real time. 
There are two main algorithmic challenges when dealing with streaming data: the stream is large and fast, 
and we need to extract information in real time from it. That means that usually we need to accept approximate 
solutions in order to use less time and memory.
Also, the data may be evolving, so our models have to adapt when there are changes in the data. \cite{MLonDataStreams}

\subsection{Increasing Volume of the Data}
When the Data items keep arriving fast and in large quantatiy an algorithm is no longer able to process the data efficiently
by using multiple passes. Instead, it has to be designed in such a way that it is able to process the data with one pass \cite{aggarwal2007data}.
\cite{MLonDataStreams} describes five requirements that an algorithm has to fullfill, if it should be able to process streaming data successfull:

\begin{itemize}
  \item Process an instance at a time, and inspect it (at least) once.
  \item Use a limited amount of time to process each instance.
  \item Use a limited amount of memory.
  \item Be ready to give an answer (prediction, clustering, patterns) at any time.
  \item Adapt to temporal changes (Concept drift).
  \label{enum:5requ}
\end{itemize}

The last point, "Adapt to temporal changes", has to do with evolving data streams and will be described further in the following 
section.

\subsection{Drift in Streaming Data}
Often there is a inherent temporal component to the stream mining process. This is because the data may evolve over time. 
This behaviour of a data stream is known as temporal locality\cite{aggarwal2007data} (also known as Concept drift)\cite{MLonDataStreams}.Therefore, 
a straight forward adaptation of one-pass mining algorithms may not be an effective solution to the task.
Thus, Stream mining algorithms need to be carefully designed with a clear focus on the evolution of the underlying data, 
wich leads the the fith requirement (see enumeration \ref{enum:5requ}) described in \cite{MLonDataStreams}.

The term Concept drift will now be descripted further.
It does not mean that the items that are observed today are not exactly the same as those that were observed yesterday. 
A more reasonable notion is that statistical properties of the data change more than what can be attributed to chance
fluctuations. To better understand this, it helps to assume that the data is in fact the result of a random process that
each time generates an item according to a probability distribution which is used at that exact time, and that may or 
may not be the same as the one which is used at any other given time. There is no change (drift) when this underlying generating distribution
remains the same. Drift occurs whenever it varies from one time step to the next \cite{MLonDataStreams}.

Often, an additional independence assumption is implicitly or explicitly used: that the item generated at time \textit{t} is 
independent of those generated at previous time steps. This assumption is often incorrect or false, because in many 
situations the stream has memory, and experiences bursts of highly correlated events. For example, a fault in a 
component of a system is likely to generate a burst of faults in related components \cite{MLonDataStreams}. 

Although Concept drift in the item distribution may be arbitrary, it helps to name a few generic types, 
which are not exclusive within a stream:

\begin{itemize}
  \item \textit{Sudden} drift occurs when the distribution has remained unchanged for a long time, then changes in a few steps to a significantly different one. It is often called \textit{shift}.
  \item \textit{Gradual} or \textit{incremental} drift occurs when, for a long time, the distribution experiences at each time step a tiny, barely noticeable change, but these accumulated changes become significant over time.
  \item Drift may be \textit{global} or \textit{partial} depending on whether it affects all of the item space or just a part of it. In ML terminology, partial change might affect only instances of certain forms, or only some of the instance attributes.
  \item \textit{Recurrent} concepts occur when distributions that have appeared in the past tend to reappear later. An example is seasonality, where summer distributions are similar among themselves and different from winter distributions. A different example is the distortions in city traffic and public transportation due to mass events or accidents, which happen at irregular, unpredictable times.
  \item In prediction scenarios, we are expected to predict some outcome feature $Y$ of an item given the values of input features $X$ observed in the item. \textit{Real} drift occurs when $Pr[Y\mid X]$ changes, with or without changes in $Pr[X]$. \textit{Virtual} drift occurs when $Pr[X]$ changes but $Pr[Y\mid X]$ remains unchanged. In other words, in \textit{real} drift the rule used to label instances changes, while in \textit{virtual} drift the input distribution changes \cite{MLonDataStreams}.
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=\columnwidth]{Concept_1}
  \caption{Visualization of types of Concept drift \cite{ConceptDrift}} 
  \label{fig:concept_1}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\columnwidth]{Concept_2}
  \caption{Visualization of real and virtual drift \cite{ConceptDrift}} 
  \label{fig:concept_2}
\end{figure}

\cite{ConceptDrift}

\section{Criteria for the Comparision}

This section will explain on what criteria this thesis will base the comparsion of the different implementations. 
It will also descirbed what the difference between the criteria is and why this is importent to know.
It will define what this thesis understands under the terms performance and accuracy, as well as what the differences
between the used error-estimations are.

\subsection{Evaluations for Data Streams}
To evaluate a learning algorithmus, it must be know which examples were used to train the algorithmus and which are used to 
test the model output by the algorithms. Which procedure is used in batch learning has partly depended on data size.
For small data sets with $<$ 1000 examples the procedure of cross-validation was well suited, as it made maximum use of the
data that it could use.
A Problem arose when the size of the data keept increasing, as this practicly created a time limit for procedures that keept
repeating the training process to many times.
For this reason it is commen practise to try to reduce the number of folds and repetitions for big data sets to allow experiments
to conclude in reasonable time. 
One way to achieve this is to take several hundreds of thousend samples in a single batch and take them for a single holdout run,
as this requires the least computational effort. The rationalization for this, beside the practical time issues, is that the 
reliability we may lose by not having repeated runs is compensated by the reliability gained by the sheer number of samples that are used. 
There are two main approaches that we have to consider for the evaluation process, the first one being Holdout and the second being 
Prequential. \cite{Bifet_datastream} \\
These two approaches will be now be described in more detail:

\begin{itemize}
  \item \textbf{Holdout}:
        It is often acceptable to measure the performance with a single holdout set when the batch learning learning 
        would otherwise reache a scale where cross-validation would be too time consuming.
        This can get very helpful, as the results of different studies can be directly compared to each other. 
        To do this, the division between the train and test set have to be predefined.
        To track model performance over time, the model can be evaluated periodically, for example, after every 
        one million training examples. Testing the model too often has potential to significantly slow the evaluation 
        process, depending on the size of the test set.
        A source for holdout dat sets are for example sets of data of the stream that have not yet been used to train 
        the learning algorithm.
        These sets could be taken from "further ahead" in the stream to be used as test sets and could then later be 
        used again to train the learning algorithm again after the testing is complete.
        This procedure would be recommandable in scenarios with concept-drift, as it would measure a model‚Äôs ability
        to adapt to the latest trends in the data.
        In scenarios without drift, a single static holdout set should be sufficent, as this would avoid varying estimates 
        between test sets.
        If it is assumed that the test set is independent and sufficently large in relation to the complexity of the 
        target concept, it can be concluded that it then will provide an accurate measurement of generalization accuracy.
        \cite{Bifet_datastream}
  \item \textbf{Prequential}:
        An alternative approach to evaluate data stream algorithm is to interleave testing with training. Each individual
        set can be used to test the model before it is used for training and then the accuracy can be incremantally updated
        from this. When it is performed in this order the model will always be tested by sets that it has not seen yet.
        This has the advantage that no holdout set is needed to perform testing. This also results in a smooth plot of 
        the accuracy over time, as each individual set will become increasingly more insignificant to the overall average.
        This approach also has its disadvantages, as it make it diffcult to accuratly seperate and measure
        training and testing times. It also obscures the true accuracy that the algorithm can achieve at agiven point, as the 
        algorithm gets punished for mistakes that it made earlier regardless of the level of accuracy they are eventually
        capable of. It also has to be said that this effect will diminish over time.
        With this approach the statistcs are updated with every set from the stream and can be recorded at this level od detail
        if desired. To increase the efficiency a sampling parameter can be used to reduce the required storage for the results,
        by recording only at periodic intervals like the holdout method.
        \cite{Bifet_datastream}
\end{itemize}

\subsection{Performance Evaluation}
In real data streams, the number of instances for each class may be evolving and changing. It may be argued that the 
prequential accuracy measure is only appropriate when all classes are balanced and have approximately the same number 
of examples. The Kappa statistic is a more sensitive measure for quantifying the predictive performance of streaming 
classifiers. \cite{MLonDataStreams}
There are 3 different versions of the Kappa statistic that are relevant for the analysis of streaming data.
The first Kappa statistc, Kappa $\kappa$, was introduced by Cohen in his work \cite{kappak} and was defined as follows:

\begin{equation}
  \kappa = \frac{p_0-p_c}{1-p_c}
\end{equation}

The quantity $p0$ is the classifier‚Äôs prequential accuracy, and $p_c$  is the probability that a chance classifier‚Äîone
that randomly assigns to each class the same number of examples as the classifier under consideration‚Äîmakes a correct 
prediction. If the classifier is always correct, then $\kappa = 1$. If its predictions coincide with the correct ones 
as often as those of a chance classifier, then $\kappa = 0$ \cite{MLonDataStreams}.
The second Kappa statistic, $\kappa_m$ \cite{kappam}, is a measure that compares against a majority class classifier $p_m$,
that is a classifier that stores a count for each of the class labels and predicts as the class of a new instance the most 
frequent class label, instead of a chance classifier:

\begin{equation}
  \kappa_m = \frac{p_0-p_m}{1-p_m}
\end{equation}

In cases where the distribution of predicted classes is substantially different from the distribution of the actual classes, 
the majority class classifier $p_m$ can perform better than a given classifier while the classifier has a positive $\kappa$ statistic \cite{MLonDataStreams}.
The third Kappa statistic that exist, is the Kappa temporal statistic \cite{kappatemp1,kappatemp2}.
It considers the presence of temporal dependencies in data streams and is defined as:

\begin{equation}
  \kappa_\textit{temp} = \frac{p_0-p'_e}{1-p'_e},
\end{equation}

where $p'_e$ is the accuracy of the No-change classifier, that is a classifier that predict the last class in the data stream. 
It does this by exploiting autocorrelation in the label assignments. It is a simple and useful classifier when the same labels appear together in bursts.
Statistic $\kappa_\textit{temp}$ takes values from 0 to 1. The interpretation is similar to that of $\kappa$: if the
classifier is perfectly correct, then $\kappa_\textit{temp} = 1$. If the classifier is achieving the same accuracy as the No-change
classifier, then $\kappa_\textit{temp} = 0$. Classifiers that outperform the No-change classifier fall between 0 and 1. Sometimes
$\kappa_\textit{temp} < 0$, which means that the classifier is performing worse than the No-change baseline \cite{MLonDataStreams}.

Using $\kappa_\textit{temp}$ instead of $\kappa_m$,we can detect misleading classifier performance for data that is not $\prod D$. 
For highly imbalanced but independently distributed data, the majority class classifier may beat the No-change classifier.
The $\kappa_\textit{temp}$ and $\kappa_m$ measures can be seen as orthogonal, since they measure different aspects of the performance \cite{MLonDataStreams}.

\subsection{Accuracy Evaluation}
Accuracy describes the ability of the classifier to correctly predict the data points in relation to the whole training set,
which can be defined as:

\begin{equation}
  Accuracy = \frac{Number of correct predictions}{Total number of predictions}
\end{equation}

For a binary classification, accuracy can also be calculated in terms of positive and negatives as follows:

\begin{equation}
  Accuracy = \frac{TP+TN}{TP+TN+FP+FN},
\end{equation}

with TP = True Positives, TN = True Negatives, FP = False Positives and FN = False Negatives.
The accuracy is often used to get an measurement of how good the classifier is at returning correct predictions. 
It should be noted that the accuracy can give a misleading result for  cases were ther is a high class imbalance.
In this case the classifier may achieve a high accuracy, but because the model is to simple the result is to crude to be of use.
A example would be, if the Label for A would occur in $99\%$ of the cases, then the prediction that every case would be A 
would have a accuracy of 99\%. This is called th Accuracy Paradox.
For this reason measurements like Kappa, $Kappa_m$ and $Kappa_temp$ are also required to get useful result of the
performeance and accuracy of a classifier \cite{MLonDataStreams}.

\section{Framework}

The following section will shortly introduce the python based scikit-multiflow framework, with which the the comperison 
of the different implementations of the RSLVQ algorithm where done.

Scikit-multiflow is a framework that is inspired by the \ac{moa}, the most popular open source framework for machine learning on data streams,
and MEKA, an open source implementation of methods for multi labeling. Scikit-multiflow is also inpired by scikit-learn, the most 
popular framework for machine learning in Python. Following the Scikit philosophy, scikit-multiflow is an open source machine-
learning framework for multi-output/multi-label and stream data. 

The Scikit-multiflow does not provide a graphical user interface like the MOA framework that it was inspired by. 
On the other hand can it be used within Jupyter notebooks, a popular interface in the data scientist community that is based 
on python. 
It is mainly a library that contains stream generators, learning methods, change detectors and evaluation methods for 
Machien learning algorithms on streaming data. 
Scilit-multiflow lays a special focus on its design, so that it is more user friendly to new user and familiar for more 
experienced ones.\cite{skmultiflow}

It achieves this by having a simple workflow that can be describe in 4 steps:

\begin{enumerate}
  \item Create a stream: \\
        A stream can be generate by use of either one of the predefined Stream generators or by importing a Stream from a file.
  \item Instantiate a classifier: \\
        In this step the user has to choose by which type of algorithm the classifikation process should be accomplished.
  \item Setup the evaluator: \\
        Next up the user has to choose if the evaluation process should be done presequential or by Hold-out method.
        Prequential-evaluation or interleaved-testthen-train evaluation, is a popular performance 
        evaluation method for the stream setting only, where tests are performed on new data before using it to train the model.
        Hold-out evaluation is a popular performance evaluation method for batch and stream settings, where tests are performed 
        in a separate test set. \cite{skmultiflow}
  \item Run the evaluation: \\
        The evaluator will perform the following subtask in this final step,
        first, it will check if there are still samples in the stream and then it will pass the next sample to the classifier,
        which will either test the sample with the \verb|predict()| method or it willl update the classefier with the \verb|partial_fit()|
        method of the clasifier.
\end{enumerate}
  
To give better understanding how this exactly works, \ref{lst:scikit} will provide a small example where a synthetic waveform gets 
generated with the WaveformGenerator. This generator will create a synthetic stream that generates default samples with
21 numeric attributes and 3 target values, based on a random differentiation of some base waveforms.
For the classifier is the Hoeffding Tree choosen with default parameters.
After this we chose a prequential evaluator with the following parameters: 
\begin{itemize}
  \item \verb|show_plot| = true, this will generate a dynamic plot that will update as the classifier is trained.
  \item \verb|pretrain_size| = 200, this parameter sets the number of samples that is used for the first training set.
  \item \verb|max_sample| = 20000, this parameter set the maximum number of samples that should be used.
\end{itemize}
In the last step we then call evaluator method, that will then update the results and the plot.
It is to note that at the time this thesis was written, the accuracy score stand for the performance 
in the framework \cite{skmultiflow}. 

\pagebreak

\begin{lstlisting}[label=lst:scikit,
  language=python,
  firstnumber=1,
  caption=Simple example of the scikit-multiflow workflow]			   

  """1. Create a stream""" 
  stream = WaveformGenerator()
  stream.prepare_for_use()
  
  """2. Instantiate the HoeffdingTree classifier"""
  ht = HoeffdingTree()
  
  """3. Setup the evaluator"""
  evaluator = EvaluatePrequential(show_plot=True,
                                  pretrain_size=200,
                                  max_samples=20000)
  
  """4. Run evaluation"""
  evaluator.evaluate(stream=stream, model=ht)
\end{lstlisting}

\begin{figure}[H]
  \centering
  \includegraphics[width=\columnwidth]{Scikit_multiflow_example}
  \caption{Result Table of the example in \ref{lst:scikit}} 
  \label{fig:sci_result_examp}
\end{figure}

\chapter{Used Algorithms}

\section{Theoretical Work}

This chapter will try to give a short explanation about how the \ac{rslvq} works and will also explain the algorithm that it is based on. 
Furthermore it will explain what momentum based gradient descent algorithms there are and how they work.
These are used in the different optimization implementation of the RSLVQ that will be compared in the later chapters. 

\subsection{Learning Vector Quantization}
The first part of the theoretical work will give an introduction to the \ac{lvq}, from that later 
the RSLVQ was derived from.
The LVQ is a class of learning algorithms for \ac{npc}.It stores a set of appropriatly chosen
prototype vectors instead of storing all the data points of a training set. This change makes the method computationally more
efficent, as it does not have to store a high number of items to which new data must be compared to for classifcation anymore.
Instead, the current data point only has to be compared to the prototypes to achieve classification.
This lead to a high popularity of the LVQ for real time applications, like i.e. speech recognition \cite{lvqEx1,lvqEx2}, 
were it was used with good success.

A NPC consists of a set $\tau = (\theta_j, c_j)^M_\textit{j=1}$ of labeled prototype vectors. The parameter $\theta_j \in \chi \equiv \R^D$
are vectors in the data space and $c_j \in \iota$, $i = 1,\dots,N_y$ are their corresponding labels. Typically, 
the number of prototypes is larger than the number of classes, such that every classification boundary is determined by 
more than one prototype.
The class $y$ of a new datapoint $x$ is determined 

\begin{itemize}
  \item by selecting the prototype $\theta_i$ which is closest to $x$,
  \begin{equation}
    y = \displaystyle\min_{i} d(x,\theta_i),
    \label{equ:LVQ1}
  \end{equation}
  where d(.,.) is the distance between data point and prototype, and
  \item by assigning the label $y$ of this prototype to the datapoint $x$.
\end{itemize}

A popular choice for $d$ is the Euclidian distance 
\begin{equation}
  d(q,p) = \sqrt{\displaystyle\sum^n_\textit{i = 1}(q_i-p_i)^2}.
  \label{equ:LVQ2}
\end{equation}
LVQ is a class of algorithm for the determination of prototype vectors for NPC, which make use of the distribution of the
training data as well as their class labels when selecting useful set of prototype vectors. 
The LVQ 2.1, for example, selects for every pair $(x,y)$, where $x$ is the data point and $y$ is the label, from
the training set $S = (x_i,y_i)^N_\textit{i=1}$, the two nearest prototypes $\theta_l,\theta_m$ (see equation \ref{equ:LVQ1} 
for selection of one prototype) according to the Euclidian distance (see equation: \ref{equ:LVQ2}).
If the labels $c_l$ and $c_m$ are different and if one of them is equal to the label $y$ of the data point, then the two nearest
prototypes are adjusted according to:

\begin{equation}
  \begin{split}
    &\theta_l(t+1) = \theta_l(t) + \alpha(t)(x-\theta_l), \quad c_l = y,\\
    &\theta_m(t+1) = \theta_m(t) - \alpha(t)(x-\theta_m), \quad c_m \neg y.
  \end{split}
  \label{equ:LVQ3}
\end{equation}

\begin{figure}[H]
  \includegraphics[width=0.75\linewidth]{LVQ}
  \caption{Graphic depiction of the LVQ classifcation task.}
  \label{fig:LVQ}
\end{figure}

If the labels $c_l$ and $c_m$ are equal or both labels differ from the label $y$ of the data point, no parameter update is being performed.
The prototype, however, is changed only if the data point $x$ is close to the classification boundry, i.e.
if it falls into a \textit{window}

\begin{equation}
    min(\frac{d(x,\theta_m)}{d(x,\theta_l)},\frac{d(x,\theta_l)}{d(x,\theta_m)}) > s, \quad where s = \frac{1-\omega}{1+\omega},
\end{equation}

of relative width $0<\omega\leq1$. This "window rule" had to be introduced, as otherwise the prototype vectors would have diverged. \cite{RSLVQOrig}

\subsection{Robust Soft Learning Vector Quantization}

The LVQ algorithm may be a popular adaptive nearest prototype classifier for multiclass classification, 
but the algorithms from this familiy had only been propsed on heuristic grounds. Seo and Obermayer then derived the 
Robust Soft Learning Vector Quantization (RSLVQ varient) in their work \cite{RSLVQOrig}. It is a LVQ that is based on 
a Gausian Mixture. It proposes an objective function which is based on a likelihood ratio and derives the
learning rule from gradient descent.

They asume that the following objective function is maximized:

\begin{equation}
  \begin{split}
    L_r &= \displaystyle\prod_{k=1}^{N} \frac{p(x_k, y_k\mid\tau)}{p(x_k, y_k\mid\tau) + p(x_k, \bar{y}_k\mid\tau)} \\
        &= \displaystyle\prod_{k=1}^{N} \frac{p(x_k, y_k\mid\tau)}{p(x_k\mid\tau)}  \overset{!}{=} max.
  \end{split}
\end{equation}

The ratio $\frac{p(x, y\mid\tau)}{p(x\mid\tau)}$ is bounded by 0 from below and bounded by 1 from above. Because of this, 
instead of optimizing the likelihood ratio, they then optimize the 
logarithm of the ratio $L_r$ like this,

\begin{equation}
    log L_r = \displaystyle\sum_{k=1}^{N}log\frac{p(x_k, y_k\mid\tau)}{p(x_k\mid\tau)} \overset{!}{=} max,
\end{equation}

were Stochastic gradient descent leads to the following learning rule:

\begin{equation}
  \theta_l(t + 1) = \theta_l(t) + \alpha(t)\frac{\partial}{\partial\theta_l} [log \frac{p(x, y\mid\tau)}{p(x\mid\tau)}]
  \label{equ:RSLVQ_1},
\end{equation}

where $\alpha(t)$ is learning rate with $\sum_{t=1}^{\infty} \alpha(t) = \infty$ and $\sum_{t=1}^{\infty} \alpha^2(t) < \infty$.
If the conditional density functions $p(x\mid j)$ are of the normalized exponential form

\begin{equation}
  p(x\mid j) = K(j) exp f(x, \theta_j), 
\end{equation}

the learning rule becomes

\begin{equation}
  \begin{split}
    &\frac{\partial}{\partial\theta_l} [log \frac{p(x, y\mid\tau)}{p(x\mid\tau)}] = \delta(c_l = y)(P_y(l\mid x) - P(l\mid x))\frac{\partial f(x, \theta_l) }{\partial\theta_l} \\
    &- \delta(c_l \neq y) P(l\mid x)\frac{\partial f(x, \theta_l) }{\partial\theta_l}.
  \end{split}
\end{equation}

where $P_y(l\mid x)$ and $P(l\mid x)$ are assigment probabilities,

\begin{equation}
  \begin{split}
    P_y(l\mid x) &= \frac{p(l) exp f(x, \theta_l)}{\displaystyle\sum_{j:c_j = y}p(j) exp f(x, \theta_j)}, \\
    P(l\mid x) &= \frac{p(l) exp f(x, \theta_l)}{\displaystyle\sum_{j=1}^{M}p(j) exp f(x, \theta_j)}.
  \end{split}
\end{equation}

$P_y(l\mid x)$ describes the (posterior) probability that the data point \textit{x} is assigned to the component \textit{l} of the mixture
, given that the data point was generated by the correct class. $P(l\mid x)$ describes the (posterior) probability that the 
data point \textit{x} is assigned to the component \textit{l} of the complete mixture using all classes.
Using the gradient given by the equation \ref{equ:RSLVQ_1}, following learning rule is obtained: 

\begin{equation}
  \theta_l(t + 1) = \theta_l(t) + \alpha(t) 
  \begin{cases}
    P_y(l\mid x) - P(l\mid x)[\frac{\partial f(x, \theta_l) }{\partial\theta_l}], &c_l = y,  \\
    - P(l\mid x)[\frac{\partial f(x, \theta_l) }{\partial\theta_l}],              &c_l \neq y.              
  \end{cases}
  \label{equ:RSLVQ_2}
\end{equation}

It has to be noted that the factor $P_y(l\mid x) - P(l\mid x)$ is always positive. \cite{RSLVQOrig}

The Cost-function and the learning rule described until now were for training the RSLVQ for the general case, but 
Seo and Obermayer provided also a varient that uses a Gaussian mixture ansatz.
In that version they choose a Gaussian mixture model whose components have similar width and strengths, i.e.
$\sigma_l = \sigma, \forall l, and$ $p(l) = \frac{1}{M}, l = 1, ..., M$. They obtain 

\begin{equation}
  f(x,\theta_l) = \frac{-(x-\theta_l)^2}{2\sigma^2},   \quad   \frac{}{}f(x,\theta_l) = \frac{1}{\sigma^2}(x-\theta_l).
\end{equation}

By substituting the derivative of $f(x,\theta_l)$ into equation \ref{equ:RSLVQ_2} they obtained

\begin{equation}
  \theta_l(t + 1) = \theta_l(t) + \alpha(t) 
  \begin{cases}
    P_y(l\mid x) - P(l\mid x)(x-\theta_l),  &c_l = y,  \\
    - P(l\mid x)(x-\theta_l),               &c_l \neq y,              
  \end{cases}
  \label{equ:RSLVQ_3}
\end{equation}

where $\alpha(t) = \frac{\alpha(t)}{\sigma^2}$ and

\begin{equation}
  \begin{split}
    P_y(l\mid x) &= \frac{exp \frac{-(x-\theta_l)^2}{2\sigma^2}}{\displaystyle\sum_{j:c_j = y} exp \frac{-(x-\theta_j)^2}{2\sigma^2}}, \\
    P(l\mid x) &= \frac{exp \frac{-(x-\theta_l)^2}{2\sigma^2}}{\displaystyle\sum_{j=1}^{M} exp \frac{-(x-\theta_j)^2}{2\sigma^2}}.
  \end{split}
  \label{equ:RSLVQ_4}
\end{equation}

The equations \ref{equ:RSLVQ_3} and \ref{equ:RSLVQ_4} implement the RSLVQ algorithm. Prototypes whose label is equal to 
the label of the data point are attracted, while prototypes with different labels are repelled. Using deterministic annealing
of $\sigma^2$, which is a hyperparameter of the learning rule described in \ref{equ:RSLVQ_3}, the RSLVQ can be optimized.
If the width $\sigma$ of the Gaussian components goes to zero, both assignment probabilities (equation \ref{equ:RSLVQ_4}),
become hard assignments. If th label $c_q$ of the nearest prototype \textit{q} is equal to the label \textit{y} of the data
point \textit{x} then no update is being performed, because 

\begin{equation}
  P(l\mid x) = P_y(l\mid x) = 0, \quad \forall l \neq q, \quad P_y(q\mid x)-P(q\mid x) = 0.
\end{equation}

Only if the label of the data point \textit{x} differs from the label of the nearest prototype \textit{q}, then

\begin{equation}
  \begin{split}
    P(l\mid x) &= 0, \forall l \neq q, \quad \quad P_y(l\mid x) = 0, \forall l \neq q',\\
    P(q\mid x) &= 1, \quad \quad \quad \quad \quad P_y(q\mid x) = 1,
  \end{split}
\end{equation}

where \textit{q'} is the nearest prototype vector with the correct class label, and the nearest prototype vector and the 
nearest correct prototypevector are changed. In the "hard" version of the RSLVQ, prototypes are modified only by the data 
points that are not correctly classified. \cite{RSLVQOrig}

Seo and Obermayer then showed in their work \cite{RSLVQOrig} for LVQ 2.1 data points which are near the current 
class boundary and which are classified correctly have the strongest effect on the update of the prototypes. In contrast to that
relies the RSLVQ on data points which are further away from the classification boundary and which are incorrectly classified,
i.e. RSLVQ learns from mistakes. Additionaly, the RSLVQ does not require a "window rule" like the LVQ 2.1, as the prototypes 
do not diverge. \cite{RSLVQOrig}

\section{Momentum Based Gradient Descent}

The following section will outline three algorithms that are widely used in the Deep Learning Community and that will later
be used to optimize the RSLVQ Algorithm in hopes to improve its performence and accuracy.

\subsection{Momentum}

SGD has trouble navigating ravines, i.e. areas where the surface curves much more steeply in one dimension than in another \cite{problemSteepLearn, overvieDiffRSLVQ},
which are common around local optima. In these scenarios, SGD oscillates across the slopes of the ravine while only making 
hesitant progress along the bottom towards the local optimum as in figure \ref{fig:SGD_momentum}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\columnwidth]{SGD_momentum}
  \caption[Diff. SGD moment.]{Differences of a SGD with and without momentum.\footnotemark} 
  \label{fig:SGD_momentum}
\end{figure}

Momentum \cite{QIAN1999145, overvieDiffRSLVQ} is a method that helps accelerate SGD in the relevant direction and dampens
oscillations as can be seen in figure . It does this by adding a fraction $\gamma $ of the update vector of the past time step to the
current update vector

\begin{equation}
\begin{split}
\textit{v}_\textit{t} &= \gamma\textit{v}_\textit{t-1} + \eta \theta - \eta\nabla_\theta \textit{J}(\theta) \\
\theta &= \theta - \textit{v}_\textit{t}
\end{split}
\end{equation}

The momentum term $\gamma $ is usualy set to 0.9 or a similar value.

In his Article, Ruder \cite{overvieDiffRSLVQ} describs it like if we would push a ball down a hill. 
The ball accumulates momentum as long as it rolls downhill, becoming faster and faster on the way 
(until it reaches its terminal velocity, if there is air resistance, i.e. $\gamma $ < 1). 
The same thing happens to our parameter updates: The momentum term increases for dimensions whose gradients
point in the same directions and reduces updates for dimensions whose gradients change directions.
As a result, we gain faster convergence and reduced oscillation.
\footnotetext{Genevieve B. Orr}

\subsection{Adagrad}
The first algorithm that will be described is the Adagrad \cite{Zeiler2012ADADELTAAA}. It has to be noted that this 
algorithm will not be part of the comparision, but as this algorithm is the base from wich the Adadelta and later the 
RMSprop were developed from, it will be shortly explained nontheless.
The Adagrad is an algorithm for gradient-based optimization that adapts to updates for each individual parameter to 
perform larger or smaller updates depending on their importance. The learning rate gets adapted to the parameters, were
it performs larger updates if the parameters are more infrequent and smaller updates if they are frequent.
Hence, it is well-suited to deal with sparse data. As other works \cite{dean2012large} have shown, this greatly improves
the robustness of SGD, which lead to its wide use to train large Neural Networks.
It was also used to train GloVe word embeddings as infrequent words require
much larger updates than frequent ones \cite{pennington2014glove, overvieDiffRSLVQ}.   

For the reason that Adagrad uses a different learning rate for every parameter $\theta_i$ at every time step \textit{t},
Adagrad's per-parameter update is first shown and then vectorized. For brevity, we set $\textit{g}_\textit{t, i}$ to be
the gradient of the objective function w.r.t. the parameter $\theta_i$ at the time step \textit{t}:

\begin{equation}
  \textit{g}_\textit{t, i} = \nabla_\textit{$\theta$ t}\textit{J}(\theta_\textit{t, i})
  \label{equ:Adagrad_1}
\end{equation}

The update for every SGD parameter $\theta_i$ at time \textit{t} becomes:

\begin{equation}
  \theta_\textit{t+1, i} = \theta_\textit{t, i} - \eta \cdot \textit{g}_\textit{t, i}
\end{equation}

In its update rule, Adagrad modifies the general learning rate $\eta$ each time step \textit{t} for every parameter
$\theta_i$ based on the past gradients that have been computed for $\theta_i$:

\begin{equation}
  \theta_\textit{t+1, i} = \theta_\textit{t, i}-\frac{\eta}{\textit{G}_\textit{t, ii} - \epsilon} \textit{g}_\textit{t, i}
\end{equation}

$\textit{G}_t$ $\in$ $\R^\textit{dxd}$ here is a diagonal matrix where each diagonal element \textit{i, i} is the sum of the
squares of the gradients w.r.t. $\theta_i$ up to time step \textit{t} \cite{AdadeltaAddition}, while $\epsilon$ is a smoothing term that avoids
division by zero (usually on the order of 1\textit{e} - 8). 

As $\textit{G}_t$ contains the sum of the squares of the past gradients w.r.t. to all parameters $\theta$ along its
diagonal, we can now vectorize our implementation by performing an element-wise matrix-vector multiplication $\odot$
between $\textit{G}_t$ and $\textit{g}_t$:

\begin{equation}
  \Delta\theta_\textit{t} = -\frac{\eta}{\sqrt{\textit{G}_\textit{t} + \epsilon}} \odot \textit{g}_\textit{t}
  \label{equ:Adagrad_2}
\end{equation}

One of Adagrad‚Äôs main benefits is that it eliminates the need to manually tune the learning rate. Most implementations 
use a default value of 0.01 and leave it at that.
Adagrad‚Äôs main weakness is its accumulation of the squared gradients in the denominator: Since every added term is 
positive, the accumulated sum keeps growing during training. This in turn causes the learning rate to shrink and eventually
become infinitesimally small, at which point the algorithm is no longer able to acquire additional knowledge. \cite{overvieDiffRSLVQ}

\subsection{Adadelta}
One of the more often used momentum-based algorithm is the Adadelta approach. It is an extension of the Adagrad that 
seeks to reduce its aggressive, monotonically decreasing learning rate. Instead of accumulating all past squared gradients, 
Adadelta restricts the window of accumulated past gradients to the fixed size $\omega$.  

Rather than inefficently storing $\omega$ previous squared gradients, the sum of gradients is recursively defined as a 
decaying average of all past squared gradients. The running average $\textit{E}[\textit{g}^2]_t$  at time step \textit{t} 
then depends (as a fraction $\gamma $ similarly to the Momentum term) only on the previous average and the 
current gradient:

\begin{equation}
\textit{E}[\textit{g}^2]_t = \gamma\textit{E}[\textit{g}^2]_\textit{t-1} + (1-\gamma)\textit{g}^2_t
\label{equ:adadelta_1}
\end{equation}

We then set $\gamma$ to a simliar value as the momentum, around 0.9. The SGD update will then be rewriten in terms of the 
parameter update vector $\Delta\theta_\textit{t}$:

\begin{equation}
  \begin{split}
    \Delta\theta_\textit{t} &= -\eta \cdot \textit{g}_\textit{t,i} \\
    \theta_\textit{t+1} &= \theta_\textit{t} - \Delta\theta_\textit{t}
  \end{split}
\end{equation}

Because of this, the parameter update vector, that is base of the parameter update vector of the Adagrad (see equation \ref{equ:Adagrad_2}), 
takes the form of:

\begin{equation}
  \Delta\theta_\textit{t} = -\frac{\eta}{\sqrt{\textit{G}_\textit{t} + \epsilon}} \odot \textit{g}_\textit{t}
\end{equation}

In the next step the diagnoal Matrix $\textit{G}_t$ gets replaced with the decaying average over past squared gradients 
$\textit{E}[\textit{g}^2]_\textit{t}$:

\begin{equation}
  \Delta\theta_\textit{t} = -\frac{\eta}{\sqrt{\textit{E}[\textit{g}^2]_\textit{t} + \epsilon}} \textit{g}_\textit{t}
\end{equation}

As the denominator is just the \ac{rms} error criterion of the gradient, we can replace
it with the criterion short-hand: 

\begin{equation}
  \Delta\theta_\textit{t} = -\frac{\eta}{RMS[\textit{g}]_t} \textit{g}_\textit{t}
\end{equation}

As in \cite{AdadeltaAddition} noted, the units in this update (as well as in the SGD, Momentum and Adagrad) do not match,
i.e. the update should have the same hypothetical units as the parameter. To realize this, they first define another 
decaying average, this time not of squared gradients but of squared parameter updates:

\begin{equation}
  \textit{E}[\Delta\theta^2]_t = \gamma\textit{E}[\Delta\theta^2]_t-1 + (1-\gamma)\Delta\theta^2_t
  \label{equ:adadelta_4}
\end{equation}

This leads to that the root mean squared error of the parameter updates is:

\begin{equation}
  \textit{RMS}[\Delta\theta]_t = \sqrt{\textit{E}[\Delta\theta^2]_t + \epsilon}
\end{equation}

Because the $\textit{RMS}[\Delta\theta]_t$ value is unknown to us, we try to approximate it with the \textit{RMS} of 
parameter updates until the previous time step. Replacing the learning rate $\eta$ in the previous update rule with $\textit{RMS}[\Delta\theta]_\textit{t-1}$
leads to the final update rule for the Adadelta:

\begin{equation}
  \begin{split}
  \Delta\theta_t &= - \frac{\textit{RMS}[\Delta\theta]_\textit{t-1}}{RMS[\textit{g}]_t} \textit{g}_\textit{t} \\
  \theta_\textit{t+1} &= \theta_t + \Delta\theta_t
  \end{split}
  \label{equ:adadelta_2}
\end{equation}

In the Adadelta we do not need to set a learning rate $\eta$, as it was eliminated from the update rule. \cite{overvieDiffRSLVQ}

\subsection{RMSprop}
RMSprop is an adaptive learning rate method proposed by Geoff Hinton in Lecture 6e of his Coursera Class. \cite{RMSprop_Hinton}
As a result of the need to resolve the Adagrad's radically diminishing learning rates, both the Adadelta and 
the RMSprop had been developed independetly from each other at the same time. RMSprop in fact is identical
to the first update vector of Adadelta that we derived above:

\begin{equation}
  \textit{E}[\textit{g}^2]_t = 0.9\textit{E}[\textit{g}^2]_\textit{t-1} + 0.1\textit{g}^2_t
  \label{equ:rmsprop_1}
\end{equation}

\begin{equation}
  \theta_\textit{t+1} = \theta_\textit{t}-\frac{\eta}{RMS[\textit{g}]_t} \textit{g}_\textit{t}
  \label{equ:rmsprop_2}
\end{equation}

RMSprop as well divides the learning rate by an exponentially decaying average of squared gradients.
Hinton suggests $\gamma$ to be set to 0.9, while a good default value for the learning rate $\eta$ is 0.001. \cite{overvieDiffRSLVQ}

\subsection{Adam}
As described in \cite{Kingma2014AdamAM}, the \ac{adam} is another way to compute the adaptive 
learning rate for each parameter. Additionly to storing an exponentially decaying average of past squared gradients
$\textit{v}_t$ like Adadelta or RMSprop, Adam also keeps an exponentially decaying average of past gradients $\textit{m}_t$,
simliar to momentum:

\begin{equation}
  \begin{split}
  \textit{m}_t &= \beta_1\textit{m}_\textit{t-1} + (1-\beta_1)\textit{g}_t \\
  \textit{v}_t &= \beta_2\textit{v}_\textit{t-1} + (1-\beta_2)\textit{g}^2_t
  \end{split}
  \label{equ:adam_1}
\end{equation}

$\textit{m}_t$ and $\textit{v}_t$ are estimates of the first moment (the mean) and the second moment (the uncentered variance)
of the gradients respectively, hence the name of the method. As $\textit{m}_t$ and $\textit{v}_t$ are initialized as vectors of 
0's, the authors of Adam observe that they are biased towards zero, especially during the initial time steps, and especially 
when the decay rates are small (i.e. $\beta_1$ and $\beta_2$ are close to 1).

To counteract these biases they compute a bias-corrected estimate of the first and second moment:

\begin{equation}
  \begin{split}
  \hat{m}_t &= \frac{\textit{m}_t}{1-\beta^t_1} \\
  \hat{v}_t &= \frac{\textit{v}_t}{1-\beta^t_2}
  \end{split}
  \label{equ:adam_2}
\end{equation}

These are then used to update the parameters just as we have seen in Adadelta and RMSprop, which yields the Adam update rule:

\begin{equation}
\theta_\textit{t+1} = \theta_\textit{t}-\frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t
\label{equ:adam_3}
\end{equation}

The authors recommend in their work to use as default values of 0.9 for $\beta_1$, 0.999 for $\beta_2$ and $10^\textit{-8}$ for $\epsilon$.
They show empirically that Adam works well in practice and compares favorably to other adaptive learning-method algorithms.
\cite{overvieDiffRSLVQ, Kingma2014AdamAM}

\begin{algorithm}
  \caption{Adam algorithm, as proposed in \cite{Kingma2014AdamAM}. The authors recommend for default settings the value
          0.9 for $\beta_1$, 0.999 for $\beta_2$ and $10^\textit{-8}$ for $\epsilon$ as well as a stepsize $\alpha$ of 0.001.}\label{euclid}
  \begin{algorithmic}[1]
    \Require $\alpha$: Stepsize
    \Require $\beta_1$, $\beta_2$ $\in$ $[0,1)$: Exponential decay rates for the moment estimates
    \Require \textit{f}$(\theta)$: Stochastic objective function with parameters $\theta$
    \Require $\theta_0$: Initial parameter vector \\
    Initialize first moment vector: $m_0 = 0$ \\
    Initialize second moment vector: $v_0 = 0$ \\
    Initialize timestep: $t = 0$ 
    \While{$\theta_t$ not converged} \\
      t = t + 1 \\
      Get the gradients at timestamp $\textit{t}: \textit{g}_t \leftarrow \nabla_\textit{$\theta$ t}\textit{J}(\theta_\textit{t-1})$ ( see equation \ref{equ:Adagrad_1}) \\
      Update first moment estimate: $\textit{m}_t \leftarrow \beta_1\textit{m}_\textit{t-1} + (1-\beta_1)\textit{g}_t$ \\
      Update second moment estimate: $\textit{v}_t \leftarrow \beta_2\textit{v}_\textit{t-1} + (1-\beta_2)\textit{g}^2_t$ \\
      Compute bias-corrected first moment estimate: $\hat{m}_t \leftarrow \frac{\textit{m}_t}{1-\beta^t_1}$ \\
      Compute bias-corrected second moment estimate: $\hat{v}_t \leftarrow \frac{\textit{v}_t}{1-\beta^t_2}$ \\
      Update the parameters: $\theta_\textit{t+1} \leftarrow \theta_\textit{t}-\frac{\eta}{\sqrt{\hat{v}_t}+ \epsilon} \hat{m}_t$ \\
    \EndWhile
    \Return Resulting parameters: $\theta_t$
  \end{algorithmic}
\end{algorithm}

\section{Implementation of the RSLVQ variants}
This chapter will show how the different RSLVQ varients where implemented, so that they can work with Streaming data.
The implementation is based on the version that was used in the scikit-multiflow framework \cite{skmultiflow} and was then further 
modiefied by Moritz Heusinger in \cite{PassiveDriftonRSLVQ}.
It has to be said that the implementation is nearly the same as in the previously mentioned work \cite{PassiveDriftonRSLVQ}.

\subsection{RSLVQ SGD}
The main differences between the different implementations of the algorithms appear in the training phase, when the prototypes
gets updated in the \texttt{\_update\_prototype} method. As the rest stays nearly the same, it will only be explained once during the explanation of how the $RSLVQ_\textit{SGD}$
varient was implemented.
In the scikit-multiflow framework the \textbf{\texttt{partial\_fit}} method, shown in listing \ref{lst:partialfit}, gets executet everytime when an algorithm initiates the
learning process or when it continous training process. It will check if the algorithm has already completed the intial 
learning process or if it is the first time that the method gets executed. If one of those 2 cases is true, the method will
continue by calling the internal \textbf{\texttt{\_validate\_train\_parms}} method, that will then carry out further checks.
If none of the 2 options is true, the method will raise an error that the algorithm has to intial the learning/training process.
After this check, the method will call the \textbf{\texttt{\_optimize}} method, that is shown in listing \ref{lst:optimize}.
It has to be noted that neither the \textbf{\texttt{partial\_fit}}, the \textbf{\texttt{\_validate\_train\_parms}} and the \textbf{\texttt{\_optimize}} methods
have been altered from how they have been implemented in the scikit-multiflow framework \cite{skmultiflow}.

\begin{lstlisting}[label=lst:partialfit,
  language=python,
  firstnumber=1,
  caption=Method \texttt{partial\_fit} from the scikit-multiflow framework]			   

  def partial_fit(self, X, y, classes=None, sample_weight=None):
        """Fit the LVQ model to the given training data and parameters using
        gradient ascent.

        Parameters
        ----------
        X : array-like, shape = [n_samples, n_features]
            Training vector, where n_samples in the number of samples and
            n_features is the number of features.
        y : numpy.ndarray of shape (n_samples, n_targets)
            An array-like with the class labels of all samples in X
        classes : numpy.ndarray, optional (default=None)
            Contains all possible/known class labels. Usage varies depending
            on the learning method.
        sample_weight : Not used.

        Returns
        --------
        self
        """
        if set(unique_labels(y)).issubset(set(self.classes_)) or self.initial_fit is True:
            X, y = self._validate_train_parms(X, y, classes=classes)
        else:
            raise ValueError('Class {} was not learned - please declare all classes in first call of fit/partial_fit'.format(y))

        self._optimize(X, y)
        return self
\end{lstlisting}

The \textbf{\texttt{\_optimize}} method will search for the the nearest correct and the nearest wrong prototype, based on 
their euclidiean distance towards the data point that has to be classified, as describe in \ref{equ:LVQ3} and visualized in \ref{fig:LVQ}.
If the correct prototype(prototype with the right label) is not the nearest to the data point, then each the model of the nearest wrong
prototype as well as the model of the nearest correct prototype should be updated by calling the \textbf{\texttt{\_update\_prototype}} method

\begin{lstlisting}[label=lst:optimize,
  language=python,
  firstnumber=1,
  caption=Method \texttt{\_optimize} from the scikit-multiflow framework]			   

  def _optimize(self, X, y):
        nb_prototypes = self.c_w_.size

        n_data, n_dim = X.shape
        prototypes = self.w_.reshape(nb_prototypes, n_dim)

        for i in range(n_data):
            xi = X[i]
            c_xi = int(y[i])
            best_euclid_corr = np.inf
            best_euclid_incorr = np.inf

            # find nearest correct and nearest wrong prototype
            for j in range(prototypes.shape[0]):
                if self.c_w_[j] == c_xi:
                    eucl_dis = euclidean_distances(xi.reshape(1, xi.size),
                                                   prototypes[j]
                                                   .reshape(1, prototypes[j]
                                                   .size))
                    if eucl_dis < best_euclid_corr:
                        best_euclid_corr = eucl_dis
                        corr_index = j
                else:
                    eucl_dis = euclidean_distances(xi.reshape(1, xi.size),
                                                   prototypes[j]
                                                   .reshape(1, prototypes[j]
                                                   .size))
                    if eucl_dis < best_euclid_incorr:
                        best_euclid_incorr = eucl_dis
                        incorr_index = j

            # Update nearest wrong prototype and nearest correct prototype
            # if correct prototype isn't the nearest
            if best_euclid_incorr < best_euclid_corr:
                self._update_prototype(j=corr_index, c_xi=c_xi, xi=xi,
                                       prototypes=prototypes)
                self._update_prototype(j=incorr_index, c_xi=c_xi, xi=xi,
                                       prototypes=prototypes)
\end{lstlisting}

The \textbf{\texttt{\_update\_prototype}}, as shown as in listing \ref{lst:sgd}, is when the first real difference to the scikit implementation appears.
The method will then compare if the prototype has the same label yi (here named as $c_\textit{xi}$) as the data point xi.
It will be then adjusted according to equation \ref{equ:RSLVQ_3}. 
$P_y(l\mid x)$ and $P(l\mid x)$ from \ref{equ:RSLVQ_4} are then calculated by the \textbf{\texttt{\_p}} method.
It uses the internal method \textbf{\texttt{\_costf}} to calculate the cost for each of the prototypes and it represents
the $\frac{-(x-\theta_l)^2}{2\sigma^2}$ part of equation \ref{equ:RSLVQ_4}. 
Both the \textbf{\texttt{\_p}} and the \textbf{\texttt{\_costf}} method are unchanged from their implementation in \cite{skmultiflow}

\begin{lstlisting}[label=lst:sgd,
  language=python,
  firstnumber=1,
  caption= Method \texttt{\_update\_prototype} as it was used in \cite{PassiveDriftonRSLVQ}.]			   

  def _update_prototype(self, j, xi, c_xi, prototypes):
        """SGD"""
        d = xi - prototypes[j]

        if self.c_w_[j] == c_xi:
            # Attract prototype to data point
            self.w_[j] += self.learning_rate * (self._p(j, xi, prototypes=self.w_, y=c_xi) -  self._p(j, xi, prototypes=self.w_)) * d
        else:
            # Distance prototype from data point
            self.w_[j] -= self.learning_rate * self._p(j, xi, prototypes=self.w_) * d
\end{lstlisting}

\subsection{RSLVQ Adadelta}

The first steps of the Adadelta implementation are the same as in the SGD implementation. In the first step the method will
again calculate the adjustment for the prototype like it was described in \ref{equ:RSLVQ_3}.
It will also calculate the Posterior and prior in the same way as described in \ref{equ:RSLVQ_4} with the \textbf{\texttt{\_p}} and
\textbf{\texttt{\_costf}} methods.
In next step is now were the differences between the implementation of the SGD and Adadelta start.
First, it will calculate the sum of the past squared gradients according to equation \ref{equ:adadelta_1}.
It will then calculate the gradient update at step t according to the first equation from \ref{equ:adadelta_2}.
As the $\textit{RMS}[\Delta\theta]_t$ value is unknown to us, we try to approximate it with the \textit{RMS} of 
parameter updates until the previous time step like this: $E[\Delta\theta^2] + \epsilon$.
This gives us:

\begin{equation}
  \Delta \theta_t = \frac{(E[\Delta\theta^2] + \epsilon)}{\sqrt{(E[\Delta\theta^2] + \epsilon)}} g_t
\end{equation}

Next we store the squared parameter updates $ $ according to equation \ref{equ:adadelta_4}.
Finally we apply the update prototype accoring to the second equation from \ref{equ:adadelta_2}:

\begin{equation}
  \theta_\textit{t+1} = \theta_t + \Delta\theta_t.
\end{equation}

This implementation of the Adadelta was also used in \cite{PassiveDriftonRSLVQ}.

\begin{lstlisting}[label=lst:adadelta,
  language=python,
  firstnumber=1,
  caption= Adadelta implementation from \cite{PassiveDriftonRSLVQ}.]			   

  """Implementation of Adadelta"""
        d = (xi - prototypes[j])

        if self.c_w_[j] == c_xi:
            gradient = (self._p(j, xi, prototypes=self.w_, y=c_xi) - self._p(j, xi, prototypes=self.w_)) * d
        else:
            gradient = - self._p(j, xi, prototypes=self.w_) * d

        # Accumulate past squared gradients
        self.squared_mean_gradient[j] = self.decay_rate *self.squared_mean_gradient[j] + (1 - self.decay_rate) * gradient ** 2

        # Compute update/step
        step = ((self.squared_mean_step[j] + self.epsilon) / (self.squared_mean_gradient[j] + self.epsilon)) **0.5 * gradient

        # Accumulate updates
        self.squared_mean_step[j] = self.decay_rate * self.squared_mean_step[j] + (1 - self.decay_rate) * step ** 2

        # Attract/Distract prototype to/from data point
        self.w_[j] += step
\end{lstlisting}

\subsection{RSLVQ RMSprop}

The implementation of the RMSprop is nearly the same as for the Adadelta, the difference is that we reintroduce the learning
rate $\eta$, that was eliminated in the Adadelta and replaced by the root mean squared error of the parameter updates $\textit{RMS}[\Delta\theta]_\textit{t-1}$.

The steps until after the posterior and prior calculation are the exact same as in the SGD implementation.
When the gradient is calculated, it will be added to the averge past squared gradients like in equation \ref{equ:rmsprop_1} described.
If we take the value $0.9$ for $\gamma$ like Hinton suggested in \cite{RMSprop_Hinton}, we get the following equation:

\begin{equation}
  G_t = 0.9\textit{E}[\textit{g}^2]_\textit{t-1} + 0.1\textit{g}^2_t 
\end{equation}

The prototype update can be calculated by equation \ref{equ:rmsprop_2}, were the $-\frac{\eta}{RMS[\textit{g}]_t} g_t$ 
part, that calculates the gradient update, can be substituted with $\Delta\theta$.
Because the RMSprop is identical to the first update vector of the Adadelta, we will then get for $\Delta\theta$ the following 
eqaution:

\begin{equation}
  \Delta\theta = - \frac{\eta}{G_t-\epsilon} \textit{g}_\textit{t}.
\end{equation}

This equation is then used to calculate the gradient update before it is update is performed on the prototype in the 
final implementation \cite{PassiveDriftonRSLVQ}.

\pagebreak

\begin{lstlisting}[label=lst:rmsprop,
  language=python,
  firstnumber=1,
  caption= Implementation of the RMSprop from \cite{PassiveDriftonRSLVQ}.]			   

  """RMSprop"""
        d = xi - prototypes[j]
                
        if self.c_w_[j] == c_xi:
            gradient = (self._p(j, xi, prototypes=self.w_, y=c_xi) - self._p(j, xi, prototypes=self.w_)) * d
        else:
            gradient = - self._p(j, xi, prototypes=self.w_) * d
            
        # Accumulate gradient
        self.squared_mean_gradient[j] = 0.9 * self.squared_mean_gradient[j] + 0.1 * gradient ** 2
        
        # Update Prototype
        self.w_[j] += (self.learning_rate / ((self.squared_mean_gradient[j] + self.epsilon) ** 0.5)) * gradient
\end{lstlisting}

\subsection{RSLVQ Adam}

As describe in chapter 3.2.5, the Adam implementation is simliar to the Adadelta and RMSprop implementation.
This means for the implementation, at the start it repeats again the same steps of the SGD algorithm by computing the gradient.
When the gradient is computed will it continue by computing the average of past  gradients $m_t$ and the average  of  past  squared  gradients $v_t$
like in equation \ref{equ:adam_1}. It has to be noted the parameters $m_t$ and $v_t$ needs to be initialized as vectors of 0's before
the computation process. This is done by modifying the \textbf{\texttt{\_optimize}} method in the end like this:

\begin{lstlisting}[label=lst:adam,
  language=python,
  firstnumber=1,
  caption= Modification of the \texttt{\_optimize} method to initialize $m_t$ and $v_t$.]			   

  if self.initial_fit:
    # Next two lines are Init for ADAM last m + v gradients
    self.gradients_v_sqrt = np.zeros_like(self.w_)
    self.gradients_m = np.zeros_like(self.w_)
    self.initial_fit = False
\end{lstlisting}

In the next step will be then the bias corrected estimates for $m_t$ and $v_t$, $\hat{m}_t$ and $\hat{v}_t$,
like in equation \ref{equ:adam_2}. 
The last step will then apply the updated rule. Implemented is this like in equation \ref{equ:adam_3} suggested.
The values $\beta_1$ and $\beta_2$ are set to 0.9 and 0.999 and $\epsilon$ is set to $10^\textit{-8}$, like it was suggested in \cite{overvieDiffRSLVQ, Kingma2014AdamAM}.

\pagebreak

\begin{lstlisting}[label=lst:adam,
  language=python,
  firstnumber=1,
  caption= Implementation of Adam on basis of \cite{PassiveDriftonRSLVQ}.]			   

  """Adam"""
        d = (xi - prototypes[j])

        """Calculate posterior"""
        if self.c_w_[j] == c_xi:
            gradient = (self._p(j, xi, prototypes=self.w_,y=c_xi) - self._p(j, xi, prototypes=self.w_))* d
        else:
            gradient = - self._p(j, xi, prototypes=self.w_)* d

        """Compute gradients m """
        self.gradients_m[j] = self.beta_1 * self.gradients_m[j] + (1 - self.beta_1) * gradient

        """Compute squared gradients v """
        self.gradients_v_sqrt[j] = self.beta_2 * self.gradients_v_sqrt[j] + (1 - self.beta_2) * gradient ** 2 

        """Compute m correction"""
        m_corrected = self.gradients_m[j] / (1 - self.beta_1)

        """Compute v correction"""
        v_corrected = self.gradients_v_sqrt[j] / (1 - self.beta_2)

        """Update prototype"""
        self.w_[j] += (self.learning_rate/(np.sqrt(v_corrected) + self.epsilon ))*m_corrected
\end{lstlisting}

\chapter{Test realisation}
This section contains a short description of the synthetic and real datasets that were used to carry out the comparisions.
It will also shortly describe the settings that were used and the reason for why these parameters were choosen.
The Tests were carried out on a Microsoft Surface Pro(2017) with an Intel Core i5-7300U with 2 x 2,6 GHz and 8GB of RAM.

\section{Used Datasets}

This section will contain a short describtion of the data streams, synthetic and real world data, that where used to 
perform the experiments.

\subsection{Synthetic data}

\begin{itemize}
  \item Agrawal\\
        The generator was introduced by Agrawal et al in \cite{agrawal1993database}, and was a common source of data for early work on scaling up 
        decision tree learners. The generator produces a stream containing nine features, six numeric and three categorical. 
        There are ten functions defined for generating binary class labels from the features. Presumably these determine 
        whether the loan should be approved. The features and functions are listed in the original paper \cite{agrawal1993database,skmultiflow}.

  \item Hyperplane\\
        Generates a problem of prediction class of a rotation hyperplane. It was used as testbed for CVFDT and VFDT in \cite{hyperplane}.
        A hyperplane in d-dimensional space is the set of points $x$ that satisfy $\sum^d_\textit{i=1} w_ix_i=w_0 = \sum^d_\textit{i=1} w_i$,
        where $x_i$ is the i-th coordinate of $x$.  Examples for which $\sum^d_\textit{i=1} w_ix_i>w_0$, are 
        labeled positive, and examples for which $\sum^d_\textit{i=1}w_ix_i\leq w_0$, are labeled negative.

        Hyperplanes are useful for simulating time-changing concepts, because the change of the orientation and position
        of the hyperplane can be done in a smooth manner by changing the relative size of the weights.
        Change can be introduced to this dataset by adding drift to each weight feature $w_i=w_i + d\sigma$, where $\sigma$ is the 
        probability that the direction of change is reversed and $d$ is the change applied to every example \cite{skmultiflow}.

  \item Sinegenerator\\
        This generator is an implementation of the data stream with abrupt concept drift, as described in Gama, Joao, et al \cite{sinegenerator}
        It generates up to 4 relevant numerical attributes, that vary from 0 to 1, where only 2 of them are relevant to 
        the classification task and the other 2 are added by request of the user. A classification function is chosen 
        among four possible ones: 
        \begin{enumerate}
          \item SINE1. Abrupt concept drift, noise-free examples. It has two relevant attributes. Each attributes has 
          values uniformly distributed in $[0;1]$. In the first context all points below the curve $y=sin(x)$ are classified as positive.
          \item Reversed SINE1. The reversed classification of SINE1.
          \item SINE2. The same two relevant attributes. The classification function is $y<0.5+0.3sin(3\pi x)$.
          \item Reversed SINE2. The reversed classification of SINE2.
        \end{enumerate}

        Concept drift can be introduced by changing the classification function. This can be done manually or using the ConceptdriftStream method
        from the scikit-multiflow framework.
        Two important features are the possibility to balance classes, which means the class distribution will tend to a uniform one, and the 
        possibility to add noise, which will, add two non relevant attributes \cite{skmultiflow}.
    
  \item Transient Chessboard\\
        Virtual drift is generated by revealing successively parts of a chessboard. This is done square by square 
        randomly chosen from the whole chessboard so that each square represents its own concept. Every time after four 
        fields have been revealed, samples covering the whole chessboard are presented. This reoccurring alternation 
        penalizes algorithms tending to discard former concepts. Only two instead of eight classes where used to reduce
        the impact of classification by chance \cite{movingsquaresChessboardRialtobridge}.


  \item Moving Squares: \\
        Four equidistantly separated, squared uniform distributions are moving in horizontal direction with constant 
        speed. The direction is inverted whenever the leading square reaches a predefined boundary. Each square 
        represents a different class. The added value of this dataset is the predefined time horizon of 120 examples 
        before old instances may start to overlap current ones. This is especially useful for dynamic sliding window 
        approaches, allowing to test whether the size is adjusted accordingly. \cite{movingsquaresChessboardRialtobridge}
        

  \item Sea Concepts: \\
        This dataset consists of 50000 instances with three attributes of which only two are relevant. 
        The two class decision boundary is given by f1 + f2 = b, where f1, f2 are the two relevant features and b a
        predefined threshold. Abrupt drift is simulated with four different concepts, by changing the value of b every 
        12500 samples. Also included are 10\verb|%| of noise. 
        This exact Datas was also used in \cite{SEADataset}.

        \begin{table}[H]
          \label{tab:synthdata}
          \centering
          \begin{tabular} {|| c c c c c c ||} 
            \hline
              Dataset & Drift &Features & Classes & Targets & Samples \\
            \hline\hline
              Agrawal & N & 9 & 2 & 1 & 40 000 \\
            \hline
              Agrawal Drift & Y & 9 & 2 & 1 & 40 000 \\
            \hline 
              Hyperplane & Y & 10 & 2 & 1 & 40 000 \\
            \hline 
              Hyperplane Drift & Y & 10 & 2 & 1 & 40 000 \\
            \hline
              Sine & Y & 2 & 2 & 1 & 40 000 \\
            \hline
              Sine Drift & Y & 2 & 2 & 1 & 40 000 \\
            \hline
              Chessboard & Y & 2 & 8 & 1 & 200 000 \\
            \hline
              Squares & N & 2 & 4 & 1 & 200 000 \\
            \hline
              Sea & Y & 3 & 2 & 1 & 50 000 \\
            \hline
          \end{tabular} 
          \caption{Overview over the synthetic generated Datasets, the streams with "Drift" in name generate the drift
          with the $ConceptDrifStream()$ method from scikit-multiflow. (Y: yes, with Drift, N: no Drift) }
        \end{table}
  
\end{itemize}

\subsection{Real world data}
This section contains the description for datasets that were taken in the real world and that were already used in other
publications. 

\begin{itemize}
  \item Weather Dataset: \\
        This dataset contains eight different features like the minimum and maximum tempreature, visibility, wind speed, 
        air pressure, etc. that were measured at the Offutt Air Force Base in Bellevue, Nebraska. These measurments were
        taken in the period of 1949-1999. The goal of this dataset is to predict if it is going to rain on certains day or not.
        It contains 18159 instances with an imbalance towards no rain (69\verb|%|) and was introduced by Elwell in \cite{weather}.

  \item Electricity Market Dataset:\\
        First described by Harris et al., it is often used for performance comparison, as it is a good benchmark for concept drift 
        classification. It holds the information of the Australian New South Wales Electricity Market, whose prices are affected 
        by supply and demand. Each sample is characterized by the following attributes: day of the week, time stamp, market demand,
        etc.. Each of the samples refers to a period of 30 minutes and the class label identiÔ¨Åes the relative change compared to the
        last 24 hours. The used Dataset is the normalized version of the original dataset that was used in \cite{MLonDataStreams}.

  \item Poker Dataset: \\
        To create this dataset, one million poker hands, each represented by five cards that got encoded with its suit and rank, 
        were randomly drawn. The class is the resulting poker hand itself such as one pair, full house and so forth.
        Since the poker hand can not change by definition and each instance was randomly generated, this dataset had 
        in its original form no drift in it.
        As this is the version as it was introduced by \cite{bifet2013efficient}, virtual drift is present in this dataset. 
        This was achieved by sorting the instances of the dataset by rank and suit. Duplicate hands were also removed.
        Additionly, this version was also normalized.

  \item Rialto Bridge Timelapse Dataset: \\
        Ten of the colorful buildings next to the famous Rialto bridge in Venice are encoded in a normalized 
        27-dimensional RGB histogram. The images were obtained from time-lapsed videos captured by a webcam with a fixed
        position. The recordings cover 20 consecutive days during may-june 2016. Continuously changing weather and 
        lighting conditions affect the representation. The labels were generated by manually masking the corresponding 
        buildings and excluded overnight recordings since they were too dark for being useful. 
        This Dataset was originaly used in \cite{movingsquaresChessboardRialtobridge}
\end{itemize}

\begin{table}[H]
  \label{tab:realdata}
  \centering
  \begin{tabular} {|| c c c c c ||} 
    \hline
      Dataset & Features & Classes & Targets & Samples \\
    \hline\hline
      Weather & 8 & 2 & 1 & 18 160 \\
    \hline 
      Electricity & 8 & 2 & 1 & 45 312 \\
    \hline
      Poker & 10 & 10 & 1 & 829 201 \\
    \hline
      Rialto & 27 & 10 & 1 & 82 250 \\
    \hline
  \end{tabular} 
  \caption{Overview over the real Datasets}
\end{table}

\section{Test Settings}

The test is run several times for each algorithm that is tested and also several times for each algorithm.
The reason for this is that each algorithm is evaluated two times in different evaluation settings.
Once it is evaluated with Holdout and once with Prequential (see section 2.3.1).
In each of the evaluation processes each of the 4 algorithm performce a evaluation on the selected datastream.
There are 13 different datastreams that will be used for the evaluation, which means that there will be $13*2*4=104$ 
runs of the evalution.
For each run will be a .csv file created and saved that will then later be condensed into 10 overview files for each of the 
evaluation metrics \ref{tab:metrics} for each of the evaluation settings.
The metrics are represented in those list as percent, so a kappa score is then listed as 0.56, which means it has a value of 56 percent.

\begin{table}[H]
  \centering
    \begin{tabular} {|| c ||} 
      \hline
        metrics \\
      \hline\hline
        Accuracy  \\
      \hline 
        Kappa  \\
      \hline
        $Kappa_m$  \\
      \hline
        $Kappa_t$  \\
      \hline
        Computation time  \\
      \hline
    \end{tabular} 
  \caption{Overview of the metrics that are recorded during the evaluation and that are then used for the comparision.}
  \label{tab:metrics}
\end{table}

Each evaluation has a set maximum number of samples that it should use and after that it will stop and then start the next evaluation.
This limit was set to 40 000, because nearly every datastream has at least 45 000 samples or more (there is 1 exception for this,
and that is the weather dataset with only 18 000 samples) and the limitation should make it easier to directly compare the computation time 
between  each of the algorithm even across different datastreams (with the exception for the weather dataset).

For the Setting of the hyperparameters of the Algorithms where mainly the recommended values from the litrature chosen. 
The parameters that exist or a shared between all/nearly all algorithms are set to the same start values.
This was done so that each algorithm had the same starting conditions as the other ones for the comparision.
The values are listed in table \ref{tab:parameters}.

\begin{table}[H]
  \centering
  \begin{tabular} {|| c c c c c c c c||} 
    \hline
      algorithm & $\sigma$ & $\epsilon$ & $\gamma*$ & $\eta*$ & $\beta 1*$ & $\beta 2*$ & Sections\\
    \hline\hline
      $RSLVQ_\textit{SGD}$ & 1 & $1e-8$ & - & - & - & - & 3.2.2\\
    \hline 
      $RSLVQ_\textit{Adadelta}$ & 1 & $1e-8$ & 0.9 & 0.001 & - & - & 3.2.3\\
    \hline
      $RSLVQ_\textit{RMSprop}$ & 1 & $1e-8$ & 0.9 & 0.001 & - & - & 3.2.4\\
    \hline
      $RSLVQ_\textit{Adam}$ & 1 & $1e-8$ & - & 0.001 & 0.9 & 0.999 & 3.2.5\\
    \hline
  \end{tabular} 
  \caption{Overview of the parameter settings for each of the algorithms. Parameters marked with a * only occured in some of the algorithms.
  ($\sigma$ = number of prototypes, $\gamma$ = decay rate, $\eta$ = learning rate)}
  \label{tab:parameters}
\end{table}

The evaluation was done in python with the scikit-multiflow framework described in section 2.4.

\chapter{Result Evaluation}
This chapter will list the results of the algorithm comparsions seperatly.
First will be the results for the Holdout setting will be described and after that the results that were produced with the 
Prequential setting. The Result Tables on which these evaluations are based on can be found in the appendix of this work.
(5 tables from the Holdout setting, 5 tables from the Prequential setting, 5 tables with ranks from the Holdout setting
and 5 tables with ranks from the Prequential setting.) 

\section{Holdout settings}
This section will provide the results of the algorithms based on their accuracy, performance measures, as described in section 2.3.2,
and their computation time with Holdout evaluation setting

\begin{itemize}
  \item \textbf{Accuracy}: \\
        Based on the Overall Accuracy score from Table \ref{tab:holdoutAcc} it can be seen that in the Holdout setting the
        normal $RSLVQ_\textit{SGD}$ implementation performs the worst in comparision to the other three implementations.
        The $RSLVQ_\textit{Adadelta}$ has the second best accuracy overall and the $RSLVQ_\textit{RMSprop}$ has the best 
        accuracy overall. The $RSLVQ_\textit{Adam}$ implementation has performed worse than the $RSLVQ_\textit{Adadelta}$
        and the $RSLVQ_\textit{RMSprop}$, but still performed better than the $RSLVQ_\textit{SGD}$.
        Looking at the results of the synthetic and real Datastreams separetly, it can be seen that the the result are the same
        for the synthetic Streams, but on the datastream based on real world Data the $RSLVQ_\textit{Adam}$ performed better then
        the $RSLVQ_\textit{Adadelta}$ and the $RSLVQ_\textit{RMSprop}$, as it was in fact the best performing implementation.
        The $RSLVQ_\textit{Adadelta}$ was still the second best implementation, while the $RSLVQ_\textit{RMSprop}$ was only the thrid 
        best implementation. The $RSLVQ_\textit{SGD}$ stayed the worst performing implementation accuracy wise.

  \item \textbf{Kappa}: \\
        In the next step the $Kappa$ score gets a closer look. The $Kappa$ score results are listed in the 
        Table \ref{tab:holdoutKappa} and on their rank in Table \ref{tab:holdoutKappaRanked}.
        In these table can be similar result observed as in the results from the Accuracy metric.
        Overall the $RSLVQ_\textit{SGD}$ again performed the worst out of all the implementations, while the $RSLVQ_\textit{Adam}$
        performed the third best again. The $RSLVQ_\textit{Adadelta}$ and $RSLVQ_\textit{RMSprop}$ switched their respectiv rank this 
        time, with the $RSLVQ_\textit{RMSprop}$ performing  the best.
        A closer look to the results of the Synthetic and real world Data streams shows something
        similar to what was already observed in the the Accuracy score.
        While the ranking of the four implementation stayed the same for the synthetic Data streams, the $RSLVQ_\textit{Adam}$ performed 
        the best again for the real Data streams. The $RSLVQ_\textit{RMSprop}$ performed the third best, while the $RSLVQ_\textit{SGD}$ and
        the $RSLVQ_\textit{Adadelta}$ stayed on their respectiv ranks of four and two.
        We can conclude from this that the $RSLVQ_\textit{Adam}$ performs the best for the Kappa score when used on real streams with the holdout
        evalution.

  \item \textbf{$Kappa_m$}: \\
        In the Tables \ref{tab:holdoutKappaM} and \ref{tab:holdoutKappaMRanked} are the results based on their $Kappa_m$ score listed.
        Based on the $Kappa_m$ score the algorithm performed the same as with the Kappa score. The $RSLVQ_\textit{RMSprop}$ performed the best 
        for the Overall result as well as for the synthetic streams only. While the $RSLVQ_\textit{Adadelta}$ was second best in the
        overall, for synthetic and real data streams. The $RSLVQ_\textit{Adam}$ was again the third best in the overall and synthetic only scores,
        while it was the best for real data streams.
        The $RSLVQ_\textit{SGD}$ was again the worst in all three.
        Based on the results from the $Kappa_m$ score the best choice for the evaluation of real world data streams would be the $RSLVQ_\textit{Adam}$
        implementation with holdout evaluation settings.

  \item \textbf{$Kappa_t$}: \\
        The Tables \ref{tab:holdoutKappaT} and \ref{tab:holdoutKappaTRanked} provide us with the metrics and the ranked values for the $Kappa_t$ score.
        This time the $RSLVQ_\textit{Adam}$ performed the best in the Overall score and again on the real data streams, while performing the third best on
        the synthetic streams. The $RSLVQ_\textit{Adadelta}$ and $RSLVQ_\textit{SGD}$ implementations stayed again on the respectively second and last place for 
        all three results. The $RSLVQ_\textit{RMSprop}$ changed from the best performing implementation overall to only the third best performing implementation
        but still stayed the best performing algorithm for synthetic generated streams.
        Based on the performance of the $Kappa_t$ score the $RSLVQ_\textit{Adam}$ is the best algorithm of the four compared for
        the evaluation of real data streams.

  \item \textbf{Computation Time}: \\
        The values for the Computation Time are listed in Table \ref{tab:holdtime} and with ranks in Table \ref{tab:holdTimeRanked}.
        In it can be seen that the $RSLVQ_\textit{SGD}$ implementation still performs the worst out of all 4 algorithms overall,
        but when used on real data streams it is the fastes computation wise.
        The fastes implementatin overall is the $RSLVQ_\textit{Adadelta}$, followed $RSLVQ_\textit{RMSprop}$ and the $RSLVQ_\textit{Adam}$.
        If we take again a seprate look at the result for the synthetic and real data streams, we can see that on the synthetic stream the 
        fastest algorithm was the $RSLVQ_\textit{RMSprop}$, followed by the $RSLVQ_\textit{Adam}$ and the $RSLVQ_\textit{RMSprop}$ 
        algorithms and with the $RSLVQ_\textit{SGD}$ being the slowest one.
        On the real data streams, as mentioned at the beginning, the $RSLVQ_\textit{SGD}$ was the fastest, followed by the $RSLVQ_\textit{RMSprop}$ and
        the $RSLVQ_\textit{Adadelta}$ algorithms, the $RSLVQ_\textit{Adam}$ algorithm being the slowest of the four.
        The computation time has shown that the other three algorithm may perform in all other metrics better than the normal 
        $RSLVQ_\textit{SGD}$ implementation, but this comes at the cost of the computation time, with all 3 taking longer than the
        $RSLVQ_\textit{SGD}$.

\end{itemize}
\section{Prequential settings}
This section will provide the results of the algorithms based on their Accuracy, Preformance measures as described in section 2.3.2
and their Computation time with Prequential evaluation setting.

\begin{itemize}
  \item \textbf{Accuracy}: \\
  The results and the rankings in respect to the Accuracy score for the algorithms are provided by the Tables \ref{tab:preqAcc} and \ref{tab:preqAccRanked}
  respectively.
  With prequential evalution enabled the $RSLVQ_\textit{SGD}$ performed the best out off all four algorithms, followed by the 
  $RSLVQ_\textit{RMSprop}$ and the $RSLVQ_\textit{Adadelta}$, with the $RSLVQ_\textit{Adam}$ performing the worst on the accuracy score.
  A separate look at the synthetic and real data stream shows that for the synthetic streams the $RSLVQ_\textit{RMSprop}$ performed the best,
  followed by the $RSLVQ_\textit{Adadelta}$ and the $RSLVQ_\textit{SGD}$ as well as the $RSLVQ_\textit{Adam}$ performing the thrid best.
  The real data streams showed the same results as the overall results, with the $RSLVQ_\textit{SGD}$ performing the best and the $RSLVQ_\textit{Adam}$ performing
  the worst out of the four streams.

  \item \textbf{Kappa}: \\
  The Tables \ref{tab:preqKappa} and \ref{tab:preqKappaRanked} provide us with the values and the rankes for the Kappa score that were taken with the
  prequentail evaluation.
  In the Overall result we can see that this time the $RSLVQ_\textit{RMSprop}$ performed the best, followed by the $RSLVQ_\textit{SGD}$ 
  and $RSLVQ_\textit{Adadelta}$ implementations. The $RSLVQ_\textit{Adam}$ performed again as the worst out of the four tested implementations.
  The synthetic streams results show on the other hand that the $RSLVQ_\textit{Adam}$ performed the best out of the four algorithms, followed by 
  the $RSLVQ_\textit{RMSprop}$ and the $RSLVQ_\textit{Adadelta}$, with the $RSLVQ_\textit{SGD}$ performing the worst on the Kappa score.
  From this we can conclude that the $RSLVQ_\textit{Adam}$ algorithm should not be taken to evaluate real world data streams when used with
  prequentail evaluation settings. Instead of it the $RSLVQ_\textit{RMSprop}$ should be taken according to the Kappa score results.
  
  \item \textbf{$Kappa_m$}: \\
  In the Tables \ref{tab:preqKappaM} and \ref{tab:preqKappaMRanked} are the results listed for the $Kappa_m$ score with prequential evaluation settings.
  The results for the $Kappa_m$ score show a simliar ranking for the overall results as the Kappa score had shown, with the 
  $RSLVQ_\textit{RMSprop}$ performing the best and the $RSLVQ_\textit{Adam}$ performing the worst again.
  For the synthetic streams the $RSLVQ_\textit{RMSprop}$ performed the best out of the four, followed by the $RSLVQ_\textit{Adadelta}$ and the
  $RSLVQ_\textit{Adam}$, with the $RSLVQ_\textit{SGD}$ performing the worst.
  On the Real data streams the $RSLVQ_\textit{SGD}$ performed the best with the $RSLVQ_\textit{RMSprop}$ still being the second best performing
  algorithm and the $RSLVQ_\textit{Adadelta}$ and $RSLVQ_\textit{Adam}$ performing as the third and fourth best algorithms respectively.
  
  \item \textbf{$Kappa_t$}: \\
  The results for the $Kappa_t$ score are provided in the Tables \ref{tab:preqKappaT} and \ref{tab:preqKappaTRanked}.
  The $RSLVQ_\textit{RMSprop}$ performed the best in the overall, synthetic and real data stream results in respect to the
  $Kappa_t$ score. The $RSLVQ_\textit{Adadelta}$ performed in the overall results as well as in the results for the synthetic streams 
  as the second best algorithm of the four, while still being the third best performing algorithm on the real data streams in regards to 
  the $Kappa_t$ score. The $RSLVQ_\textit{Adadelta}$ performed the worst on the synthetic streams, while still performing the third best on 
  the real data streams and third best on the overall results.
  The $RSLVQ_\textit{Adam}$ performed the worst of the four algorithms on the overal and real data stream results, while only performing the third best
  on the synthetic streams according to the $Kappa_t$.
  According to the results of the $Kappa_t$ score as well as the results of the other Kappa scores and the Accuracy score, it can 
  be concluded that if the evaluation takes place with prequential settings, the algorithm that would return the best results would be the
  $RSLVQ_\textit{RMSprop}$.
  
  \item \textbf{Computation Time}: \\
  The results for the Computation Time are stored in Table \ref{tab:preqTime} and with ranking in Table \ref{tab:preqtimeRanked}.
  The overall fastest algorithm with prequential evaluation settings was the $RSLVQ_\textit{Adam}$ algorithm, followed by the 
  $RSLVQ_\textit{SGD}$, the $RSLVQ_\textit{Adadelta}$ and the $RSLVQ_\textit{RMSprop}$ algorithm being the slowest of the four.
  Looking at the synthetic streams seperatly, it can be seen that the $RSLVQ_\textit{SGD}$ was the fastest this time,
  followed by the $RSLVQ_\textit{Adadelta}$ and the $RSLVQ_\textit{Adam}$, with the $RSLVQ_\textit{RMSprop}$ being the slowest again.
  On the real data streams it can be seen that the $RSLVQ_\textit{Adam}$ was again the fastest implementation, while the $RSLVQ_\textit{SGD}$
  was the second fastest and the $RSLVQ_\textit{RMSprop}$ being the third fastest.
  The computation time shows again that the algorithm that will return the best results will need some extra time to compute
  these results.
  It also showed that overall the $RSLVQ_\textit{Adam}$ may have performed faster than under the Holdout settings, but because of that
  the results were worse than before.
  
\end{itemize}

\chapter{Summary}
The Test results have shown that the $RSLVQ_\textit{Adam}$ does indeed perform Favourable in regards to the $RSLVQ_\textit{Adadelta}$ and the
$RSLVQ_\textit{RMSprop}$ under Holdout evaluation settings, like it was described in \cite{Kingma2014AdamAM}.
It had also shown that the $RSLVQ_\textit{Adadelta}$, $RSLVQ_\textit{RMSprop}$ and the $RSLVQ_\textit{Adam}$ all perform better
towards the standard $RSLVQ_\textit{SGD}$ under this setting.
The only result where all three performed worse than the standard $RSLVQ_\textit{SGD}$ implementation was the Computation time,
but this can be explained by the fact the algorithms are more complex than the $RSLVQ_\textit{SGD}$ and due to this taking more time
to compute the results.
The $RSLVQ_\textit{Adam}$ also performed consistently good on the evaluation of real world data streams, when they were evaluated with 
Holdout settings.
It should be noted that on synthetic streams the $RSLVQ_\textit{Adam}$ performed worse than the $RSLVQ_\textit{Adadelta}$ and the $RSLVQ_\textit{RMSprop}$
implementations, so for the evaluation under holdout settings the other ones should be preferred for use rather than the $RSLVQ_\textit{Adam}$.

If the evluation is done with prequential settings, the $RSLVQ_\textit{Adam}$ performed worse than either the
$RSLVQ_\textit{Adadelta}$, $RSLVQ_\textit{RMSprop}$ and the $RSLVQ_\textit{SGD}$, while the $RSLVQ_\textit{RMSprop}$ 
returned the best results under this setting.
It should also be noted that if the evaluation is only done on a synthetic stream, the $RSLVQ_\textit{Adam}$ could be taken as a 
possible alternative to the $RSLVQ_\textit{RMSprop}$ or the $RSLVQ_\textit{Adadelta}$, as it only performs a little bit worse than the other two in this case,
but is faster in regards to the computation time in comparision to the other two.

\backmatter
%%%%%%%%%%%%%%%%%%%
%% create abbreviations list
%%%%%%%%%%%%%%%%%%%

\printacronyms[include-classes=abbrev,name=Abbreviations]

%%%%%%%%%%%%%%%%%%%
%% create figure list
%%%%%%%%%%%%%%%%%%%

\listoffigures
\addcontentsline{toc}{chapter}{Table of Contents}			

%%%%%%%%%%%%%%%%%%%
%% create tables list
%%%%%%%%%%%%%%%%%%%
\listoftables

%%%%%%%%%%%%%%%%%%%
%% create listings list
%%%%%%%%%%%%%%%%%%%
%\lstlistoflistings
%\addcontentsline{toc}{chapter}{Listings}				

\printbibliography
\addcontentsline{toc}{chapter}{Literature}				

%%%%%%%%%%%%%%%%%%%
%% declaration on oath
%%%%%%%%%%%%%%%%%%%

\addchap{Eidesstattliche Erkl√§rung}

Hiermit versichere ich, dass ich die vorgelegte Bachelorarbeit selbstst√§ndig verfasst und noch nicht anderweitig zu Pr√ºfungszwecken vorgelegt habe. Alle benutzten Quellen und Hilfsmittel sind angegeben, w√∂rtliche und sinngem√§√üe Zitate wurden als solche gekennzeichnet.

\vspace{20pt}
\begin{flushright}
$\overline{~~~~~~~~~~~~~~~~~\mbox{\BaAuthor, am \today}~~~~~~~~~~~~~~~~~}$
\end{flushright}
\pagebreak

%%%%%%%%%%%%%%%%%%%
%% Appendices
%%%%%%%%%%%%%%%%%%%

\begin{appendices}
  \section{Result Tables} 

    \subsection{Holdout results}
      \begin{itemize}
        \item \textbf{Accuracy:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/HoldoutAccuracy.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Accuracy values for the Holdout evaluation.}
          \label{tab:holdoutAcc}
        \end{table}
        \pagebreak

        \item \textbf{Kappa:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/HoldoutKappa.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Kappa values for the Holdout evaluation.}
          \label{tab:holdoutKappa}
        \end{table}
        \pagebreak

        \item \textbf{$Kappa_m$:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/HoldoutKappaM.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{$Kappa_m$ values for the Holdout evaluation.}
          \label{tab:holdoutKappaM}
        \end{table}
        \pagebreak

        \item \textbf{$Kappa_t$:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/HoldoutKappaT.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{$Kappa_t$ values for the Holdout evaluation.}
          \label{tab:holdoutKappaT}
        \end{table}
        \pagebreak

        \item \textbf{Computation time:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/HoldoutCompTime.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Computation Time for the Holdout evaluation.}
          \label{tab:holdtime}
        \end{table}
        \pagebreak
      \end{itemize}

    \subsection{Prequential results}
      \begin{itemize}
        \item \textbf{Accuracy:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/PrequentialAccuracy.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Accuracy values for the Prequential evaluation.}
          \label{tab:preqAcc}
        \end{table}
        \pagebreak

        \item \textbf{Kappa:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/PrequentialKappa.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Kappa values for the Prequential evaluation.}
          \label{tab:preqKappa}
        \end{table}
        \pagebreak

        \item \textbf{$Kappa_m$:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/PrequentialKappaM.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{$Kappa_m$ values for the Prequential evaluation.}
          \label{tab:preqKappaM}
        \end{table}
        \pagebreak

        \item \textbf{$Kappa_t$:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/PrequentialKappaT.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{$Kappa_t$ values for the Prequential evaluation.}
          \label{tab:preqKappaT}
        \end{table}
        \pagebreak

        \item \textbf{Computation time:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/PrequentialCompTime.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Computation Time for the Prequential evaluation.}
          \label{tab:preqTime}
        \end{table}
        \pagebreak
      \end{itemize}

  \section{Ranked Result Tables}

    \subsection{Holdout results}
      \begin{itemize}
        \item \textbf{Ranked Accuracy:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/HoldoutAccuracyRanked.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Ranked Accuracy for the Holdout evaluation.}
          \label{tab:holdoutAccRanked}
        \end{table}
        \pagebreak

        \item \textbf{Ranked Kappa:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/HoldoutKappaRanked.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Ranked Kappa for the Holdout evaluation.}
          \label{tab:holdoutKappaRanked}
        \end{table}
        \pagebreak

        \item \textbf{Ranked $Kappa_m$:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/HoldoutKappaMRanked.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Ranked $Kappa_m$ for the Holdout evaluation.}
          \label{tab:holdoutKappaMRanked}
        \end{table}
        \pagebreak

        \item \textbf{Ranked $Kappa_t$:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/HoldoutKappaTRanked.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Ranked $Kappa_t$ for the Holdout evaluation.}
          \label{tab:holdoutKappaTRanked}
        \end{table}
        \pagebreak

        \item \textbf{Ranked Computation time:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/HoldoutCompTimeRanked.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Ranked Computation Time for the Holdout evaluation.}
          \label{tab:holdTimeRanked}
        \end{table}
        \pagebreak
      \end{itemize}

    \subsection{Prequential results}
      \begin{itemize}
        \item \textbf{Ranked Accuracy:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/PrequentialAccuracyRanked.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Ranked Accuracy for the Prequential evaluation.}
          \label{tab:preqAccRanked}
        \end{table}
        \pagebreak

        \item \textbf{Ranked Kappa:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/PrequentialKappaRanked.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Ranked Kappa for the Prequential evaluation.}
          \label{tab:preqKappaRanked}
        \end{table}
        \pagebreak

        \item \textbf{Ranked $Kappa_m$:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/PrequentialKappaMRanked.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Ranked $Kappa_m$ for the Prequential evaluation.}
          \label{tab:preqKappaMRanked}
        \end{table}
        \pagebreak

        \item \textbf{Ranked $Kappa_t$:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/PrequentialKappaTRanked.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Ranked $Kappa_t$ for the Prequential evaluation.}
          \label{tab:preqKappaTRanked}
        \end{table}
        \pagebreak

        \item \textbf{Ranked Computation time:} \\
        \begin{table}[H]
          \begin{tabular}{|c|c|c|c|c|}\hline%
            \bfseries{Data Stream} & \bfseries{$RSLVQ_\textit{SGD}$} & \bfseries $RSLVQ_\textit{Adadelta}$ & \bfseries $RSLVQ_\textit{RMSprop}$ & \bfseries $RSLVQ_\textit{Adam}$ \\\hline\hline
            \csvreader[late after line=\\\hline]%
            {results/processedResults/PrequentialCompTimeRanked.csv}%
            {DataStream = \DataStream, RSLVQSGD = \RSLVQSGD, RSLVQAdadelta = \RSLVQAdadelta, RSLVQRMSprop = \RSLVQRMSprop, RSLVQAdam = \RSLVQAdam}%
            {\DataStream & \RSLVQSGD & \RSLVQAdadelta & \RSLVQRMSprop & \RSLVQAdam}%
          \end{tabular}
          \caption{Ranked Computation Time for the Prequential evaluation.}
          \label{tab:preqtimeRanked}
        \end{table}
        \pagebreak
      \end{itemize}

      \subsection{List of contents on USB stick}
      \begin{itemize}
        \item 
      \end{itemize}

\end{appendices}

\end{document}